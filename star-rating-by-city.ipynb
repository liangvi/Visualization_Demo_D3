{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack, coo_matrix\n",
    "\n",
    "import string\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import nltk\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = pd.read_json('yelp_dataset/business.json', lines=True)\n",
    "#checkin = pd.read_json('yelp_dataset/checkin.json', lines=True)\n",
    "#photo = pd.read_json('yelp_dataset/photo.json', lines=True)\n",
    "#review =  pd.read_json('yelp_dataset/review.json', lines=True)\n",
    "#tip = pd.read_json('yelp_dataset/tip.json', lines=True)\n",
    "##user = pd.read_json('yelp_dataset/user.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2818 E Camino Acequia Drive</td>\n",
       "      <td>{'GoodForKids': 'False'}</td>\n",
       "      <td>1SWheh84yJXfytovILXOAQ</td>\n",
       "      <td>Golf, Active Life</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>33.522143</td>\n",
       "      <td>-112.018481</td>\n",
       "      <td>Arizona Biltmore Golf Club</td>\n",
       "      <td>85016</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30 Eglinton Avenue W</td>\n",
       "      <td>{'RestaurantsReservations': 'True', 'GoodForMe...</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Specialty Food, Restaurants, Dim Sum, Imported...</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>{'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.605499</td>\n",
       "      <td>-79.652289</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>L5R 3E7</td>\n",
       "      <td>128</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10110 Johnston Rd, Ste 15</td>\n",
       "      <td>{'GoodForKids': 'True', 'NoiseLevel': 'u'avera...</td>\n",
       "      <td>gnKjwL_1w79qoiV3IC_xQQ</td>\n",
       "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>{'Monday': '17:30-21:30', 'Wednesday': '17:30-...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.092564</td>\n",
       "      <td>-80.859132</td>\n",
       "      <td>Musashi Japanese Restaurant</td>\n",
       "      <td>28210</td>\n",
       "      <td>170</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15655 W Roosevelt St, Ste 237</td>\n",
       "      <td>None</td>\n",
       "      <td>xvX2CttrVhyG2z1dFg_0xw</td>\n",
       "      <td>Insurance, Financial Services</td>\n",
       "      <td>Goodyear</td>\n",
       "      <td>{'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>33.455613</td>\n",
       "      <td>-112.395596</td>\n",
       "      <td>Farmers Insurance - Paul Lorenz</td>\n",
       "      <td>85338</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4209 Stuart Andrew Blvd, Ste F</td>\n",
       "      <td>{'BusinessAcceptsBitcoin': 'False', 'ByAppoint...</td>\n",
       "      <td>HhyxOkGAM07SRYtlQ4wMFQ</td>\n",
       "      <td>Plumbing, Shopping, Local Services, Home Servi...</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>{'Monday': '7:0-23:0', 'Tuesday': '7:0-23:0', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.190012</td>\n",
       "      <td>-80.887223</td>\n",
       "      <td>Queen City Plumbing</td>\n",
       "      <td>28217</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          address  \\\n",
       "0     2818 E Camino Acequia Drive   \n",
       "1            30 Eglinton Avenue W   \n",
       "2       10110 Johnston Rd, Ste 15   \n",
       "3   15655 W Roosevelt St, Ste 237   \n",
       "4  4209 Stuart Andrew Blvd, Ste F   \n",
       "\n",
       "                                          attributes             business_id  \\\n",
       "0                           {'GoodForKids': 'False'}  1SWheh84yJXfytovILXOAQ   \n",
       "1  {'RestaurantsReservations': 'True', 'GoodForMe...  QXAEGFB4oINsVuTFxEYKFQ   \n",
       "2  {'GoodForKids': 'True', 'NoiseLevel': 'u'avera...  gnKjwL_1w79qoiV3IC_xQQ   \n",
       "3                                               None  xvX2CttrVhyG2z1dFg_0xw   \n",
       "4  {'BusinessAcceptsBitcoin': 'False', 'ByAppoint...  HhyxOkGAM07SRYtlQ4wMFQ   \n",
       "\n",
       "                                          categories         city  \\\n",
       "0                                  Golf, Active Life      Phoenix   \n",
       "1  Specialty Food, Restaurants, Dim Sum, Imported...  Mississauga   \n",
       "2                  Sushi Bars, Restaurants, Japanese    Charlotte   \n",
       "3                      Insurance, Financial Services     Goodyear   \n",
       "4  Plumbing, Shopping, Local Services, Home Servi...    Charlotte   \n",
       "\n",
       "                                               hours  is_open   latitude  \\\n",
       "0                                               None        0  33.522143   \n",
       "1  {'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...        1  43.605499   \n",
       "2  {'Monday': '17:30-21:30', 'Wednesday': '17:30-...        1  35.092564   \n",
       "3  {'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...        1  33.455613   \n",
       "4  {'Monday': '7:0-23:0', 'Tuesday': '7:0-23:0', ...        1  35.190012   \n",
       "\n",
       "    longitude                             name postal_code  review_count  \\\n",
       "0 -112.018481       Arizona Biltmore Golf Club       85016             5   \n",
       "1  -79.652289       Emerald Chinese Restaurant     L5R 3E7           128   \n",
       "2  -80.859132      Musashi Japanese Restaurant       28210           170   \n",
       "3 -112.395596  Farmers Insurance - Paul Lorenz       85338             3   \n",
       "4  -80.887223              Queen City Plumbing       28217             4   \n",
       "\n",
       "   stars state  \n",
       "0    3.0    AZ  \n",
       "1    2.5    ON  \n",
       "2    4.0    NC  \n",
       "3    5.0    AZ  \n",
       "4    4.0    NC  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    \"\"\"\n",
    "    Modified from\n",
    "    http://adataanalyst.com/scikit-learn/countvectorizer-sklearn-example/\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation, and digits \n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    stemmer = EnglishStemmer()\n",
    "   \n",
    "    # Check characters to see if they are in punctuation\n",
    "    clean = [char for char in text if (char not in string.punctuation) \n",
    "            and (not char.isdigit())] \n",
    " \n",
    "    clean = ''.join(clean)\n",
    "    tokens = clean.split()\n",
    "    tokens = [stemmer.stem(c) for c in tokens]\n",
    "    # Join the characters again to form the string.\n",
    "\n",
    "    tokens = ' '.join(tokens)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pandas-dev/pandas/issues/18152\n",
    "\n",
    "max_records = 1e5\n",
    "df = pd.read_json('yelp_dataset/review.json', lines=True, chunksize=max_records)\n",
    "reviews = pd.DataFrame() # Initialize the dataframe\n",
    "try:\n",
    "   for df_chunk in df:\n",
    "       reviews = pd.concat([reviews, df_chunk])\n",
    "except ValueError:\n",
    "       print ('\\nSome messages in the file cannot be parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = reviews.join(business, lsuffix='_r', rsuffix='_b', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined.shape)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = joined['categories'].str.contains('Restaurants', regex=False)\n",
    "temp = temp.fillna(False)\n",
    "joined = joined[temp]\n",
    "print(joined.shape)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get city list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['city'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['categories'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good/bad breakdown for given categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cats = ['Pizza', 'Mexican', 'Chinese', 'Italian', 'Vietnamese']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = joined['categories'].str.contains('Pizza', regex=False)\n",
    "temp = temp.fillna(False)\n",
    "pizza = joined[temp]\n",
    "pizza.loc[pizza['stars_r'] > 3, 'review_type'] = \"good\"\n",
    "pizza.loc[pizza['stars_r'] <= 3, 'review_type'] = \"bad\"\n",
    "p_types = pizza['review_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mexican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = joined['categories'].str.contains('Mexican', regex=False)\n",
    "temp = temp.fillna(False)\n",
    "mexican = joined[temp]\n",
    "mexican.loc[mexican['stars_r'] > 3, 'review_type'] = \"good\"\n",
    "mexican.loc[mexican['stars_r'] <= 3, 'review_type'] = \"bad\"\n",
    "m_types = mexican['review_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = joined['categories'].str.contains('Chinese', regex=False)\n",
    "temp = temp.fillna(False)\n",
    "chinese = joined[temp]\n",
    "chinese.loc[chinese['stars_r'] > 3, 'review_type'] = \"good\"\n",
    "chinese.loc[chinese['stars_r'] <= 3, 'review_type'] = \"bad\"\n",
    "c_types = chinese['review_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = joined['categories'].str.contains('Italian', regex=False)\n",
    "temp = temp.fillna(False)\n",
    "italian = joined[temp]\n",
    "italian.loc[italian['stars_r'] > 3, 'review_type'] = \"good\"\n",
    "italian.loc[italian['stars_r'] <= 3, 'review_type'] = \"bad\"\n",
    "i_types = italian['review_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = joined['categories'].str.contains('Vietnamese', regex=False)\n",
    "temp = temp.fillna(False)\n",
    "vietnamese = joined[temp]\n",
    "vietnamese.loc[vietnamese['stars_r'] > 3, 'review_type'] = \"good\"\n",
    "vietnamese.loc[vietnamese['stars_r'] <= 3, 'review_type'] = \"bad\"\n",
    "v_types = vietnamese['review_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_types[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'bad': [p_types[1], m_types[1], c_types[1], i_types[1], v_types[1]], 'good': [p_types[0], m_types[0], c_types[0], i_types[0], v_types[0]]}\n",
    "review_types = pd.DataFrame(data=d, index=['Pizza', 'Mexican', 'Chinese', 'Italian', 'Vietnamese'])\n",
    "review_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_types['index'] = review_types.index\n",
    "review_types.to_csv(\"static/data/review_types.csv\", sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good/bad breakdown for given cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Las Vegas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv = joined[joined['city'] == \"Las Vegas\"]\n",
    "lv.loc[lv['stars_r'] > 3, 'review_type'] = \"good\"\n",
    "lv.loc[lv['stars_r'] <= 3, 'review_type'] = \"bad\"\n",
    "lv_types = lv['review_type'].value_counts()\n",
    "lv_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = joined[joined['city'] == \"Phoenix\"]\n",
    "ph.loc[ph['stars_r'] > 3, 'review_type'] = \"good\"\n",
    "ph.loc[ph['stars_r'] <= 3, 'review_type'] = \"bad\"\n",
    "ph_types = ph['review_type'].value_counts()\n",
    "ph_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Madison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = joined[joined['city'] == \"Madison\"]\n",
    "mad.loc[mad['stars_r'] > 3, 'review_type'] = \"good\"\n",
    "mad.loc[mad['stars_r'] <= 3, 'review_type'] = \"bad\"\n",
    "mad_types = mad['review_type'].value_counts()\n",
    "mad_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pittsburgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit = joined[joined['city'] == \"Pittsburgh\"]\n",
    "pit.loc[pit['stars_r'] > 3, 'review_type'] = \"good\"\n",
    "pit.loc[pit['stars_r'] <= 3, 'review_type'] = \"bad\"\n",
    "pit_types = pit['review_type'].value_counts()\n",
    "pit_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charlotte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cha = joined[joined['city'] == \"Charlotte\"]\n",
    "cha.loc[cha['stars_r'] > 3, 'review_type'] = \"good\"\n",
    "cha.loc[cha['stars_r'] <= 3, 'review_type'] = \"bad\"\n",
    "cha_types = cha['review_type'].value_counts()\n",
    "cha_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'bad': [lv_types[1], ph_types[1], mad_types[1], pit_types[1], cha_types[1]], 'good': [lv_types[0], ph_types[0], mad_types[0], pit_types[0], cha_types[0]]}\n",
    "city_review_types = pd.DataFrame(data=d, index=['Las Vegas', 'Phoenix', 'Madison', 'Pittsburgh', 'Charlotte'])\n",
    "city_review_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_review_types['index'] = city_review_types.index\n",
    "city_review_types.to_csv(\"static/data/city_review_types.csv\", sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.w3schools.com/python/ref_string_join.asp\n",
    "def tokenize(string):\n",
    "    d = []\n",
    "    tokens = nltk.word_tokenize(string)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    for x in tags:\n",
    "        if x[1] == \"NN\" or x[1] == \"NNS\" or x[1] == \"NNP\" or x[1] == \"NNPS\":\n",
    "            d.append(x[0])\n",
    "    d = \" \".join(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = joined[['text', 'city', 'categories']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, joined['stars_r'], test_size=0.2, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = X_train['text']\n",
    "vectorizer = TfidfVectorizer(min_df = 0.01)\n",
    "\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "tf_train = vectorizer.transform(corpus)\n",
    "tf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "test_corpus = X_test['text']\n",
    "tf_test = vectorizer.transform(test_corpus)\n",
    "tf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf_train = pd.SparseDataFrame(tf_train.toarray(),columns=vectorizer.get_feature_names(),index=X_trainC.index)\n",
    "tf_test = pd.SparseDataFrame(tf_test.toarray(),columns=vectorizer.get_feature_names(),index=X_testC.index)\n",
    "tf_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common_cats = ['Nightlife', 'Pizza', 'Burger', 'Chinese', 'Steak', 'Sandwiches', 'Fast Food']\n",
    "common_cats = ['Pizza', 'Mexican', 'Chinese', 'Italian', 'Vietnamese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in common_cats:\n",
    "    X_train[cat] = 0\n",
    "    X_test[cat] = 0\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/36909977/update-row-values-where-certain-condition-is-met-in-pandas\n",
    "for cat in common_cats:\n",
    "    X_train.loc[X_train['categories'].str.contains(cat, regex=False), [cat]] = 1\n",
    "    X_test.loc[X_test['categories'].str.contains(cat, regex=False), [cat]] = 1\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['city'] = X_train['city'].str.lower()\n",
    "X_test['city'] = X_test['city'].str.lower()\n",
    "\n",
    "#X_train['state'] = X_train['state'].str.lower()\n",
    "#X_test['state'] = X_test['state'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X_train['city'].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainC = enc.transform(X_train['city'].reshape(-1,1))\n",
    "X_testC = enc.transform(X_test['city'].reshape(-1,1))\n",
    "X_trainC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = []\n",
    "for t in enc.categories_:\n",
    "    for c in t:\n",
    "        cities.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df = pd.SparseDataFrame(X_trainC, columns=cities)\n",
    "list(city_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enc.inverse_transform([[\"phoenix\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[common_cats].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cats = csr_matrix(X_train[common_cats].values) \n",
    "X_test_cats = csr_matrix(X_test[common_cats].values)\n",
    "X_train_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genCity(city):\n",
    "    row = pd.DataFrame(columns=cities)\n",
    "    row.loc[0] = [0]*len(cities)\n",
    "    row.loc[:, city] = 1\n",
    "    row = row.astype('int64')\n",
    "    row = csr_matrix(row.values)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genCity(\"agincourt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainJ = hstack([tf_train, X_trainC, X_train_cats], format=\"csr\")\n",
    "X_testJ = hstack([tf_test, X_testC, X_test_cats], format=\"csr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"alpha\":[0.0001, 0.001, 0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "ridge_grid = GridSearchCV(estimator=ridge, param_grid=parameters, cv=10, scoring=\"r2\", n_jobs=20)\n",
    "print(ridge_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "ridge_grid.fit(X_trainJ, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(ridge_grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = ridge_grid.cv_results_['mean_test_score']\n",
    "stds = ridge_grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, ridge_grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_grid = GridSearchCV(estimator=lasso, param_grid=parameters, cv=10, scoring=\"r2\", n_jobs=20)\n",
    "print(lasso_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_grid.fit(X_trainJ, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(lasso_grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = lasso_grid.cv_results_['mean_test_score']\n",
    "stds = lasso_grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, lasso_grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElasticNet = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_grid = GridSearchCV(estimator=ElasticNet, param_grid=parameters, cv=10, scoring=\"r2\", n_jobs=20)\n",
    "print(en_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_grid.fit(X_trainJ, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(en_grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = en_grid.cv_results_['mean_test_score']\n",
    "stds = en_grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, en_grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_final = ElasticNet(alpha=0.0001)\n",
    "en_final.fit(X_trainJ, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = en_final.predict(X_testJ)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genCat(cat, common_cats):\n",
    "    row = pd.DataFrame(columns=common_cats)\n",
    "    row.loc[0] = [0]*len(common_cats)\n",
    "    row.loc[:, cat] = 1\n",
    "    row = row.astype('int64')\n",
    "    row = csr_matrix(row.values)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(text, city, cat):\n",
    "\n",
    "    text_tf = vectorizer.transform(text)\n",
    "    text_enc = genCity(city)\n",
    "    cat_row = genCat(cat, common_cats)\n",
    "\n",
    "    text_joined = hstack([text_tf, text_enc, cat_row], format=\"csr\")\n",
    "    return text_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_size([\"this is a review\"], \"las vegas\", \"Pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(common_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def predict(text):\n",
    "\n",
    "    text_tf = vectorizer.transform(text)\n",
    "\n",
    "    #text_lower = text.str.lower()\n",
    "    text_lower = text[0].lower()\n",
    "\n",
    "    #text_enc = enc.transform(text_lower.reshape(-1,1))\n",
    "    text_enc = enc.transform([[text_lower]])\n",
    "\n",
    "    text_joined = hstack([text_tf, text_enc], format=\"csr\")\n",
    "    return en_final.predict(text_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def predict_city(text, city):\n",
    "\n",
    "    text_tf = vectorizer.transform(text)\n",
    "    text_enc = genCity(city)\n",
    "\n",
    "    text_joined = hstack([text_tf, text_enc], format=\"csr\")\n",
    "    return en_final.predict(text_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_city_cat(text, city, cat):\n",
    "\n",
    "    text_tf = vectorizer.transform(text)\n",
    "    text_enc = genCity(city)\n",
    "    cat_row = genCat(cat, common_cats)\n",
    "\n",
    "    text_joined = hstack([text_tf, text_enc, cat_row], format=\"csr\")\n",
    "    return en_final.predict(text_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(predict([\"this is a review\"]))\n",
    "print(predict([\"This is a great restaurant!\"]))\n",
    "print(predict([\"This is a bad restaurant!\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(predict_city([\"this is a review\"], \"phoenix\"))\n",
    "print(predict_city([\"this is a review\"], \"las vegas\"))\n",
    "#print(predict_city([\"this is a review\"], \"boston\"))\n",
    "print()\n",
    "print(predict_city([\"This is a great restaurant!\"], \"phoenix\"))\n",
    "print(predict_city([\"This is a great restaurant!\"], \"las vegas\"))\n",
    "#print(predict_city([\"This is a great restaurant!\"], \"boston\"))\n",
    "print()\n",
    "print(predict_city([\"This is a bad restaurant!\"], \"phoenix\"))\n",
    "print(predict_city([\"This is a bad restaurant!\"], \"las vegas\"))\n",
    "#print(predict_city([\"This is a bad restaurant!\"], \"boston\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_city_cat([\"this is a review\"], \"phoenix\", \"Pizza\"))\n",
    "print(predict_city_cat([\"this is a review\"], \"las vegas\", \"Pizza\"))\n",
    "print(predict_city_cat([\"this is a review\"], \"phoenix\", \"Chinese\"))\n",
    "print(predict_city_cat([\"this is a review\"], \"las vegas\", \"Chinese\"))\n",
    "print()\n",
    "print(predict_city_cat([\"This is a great restaurant!\"], \"phoenix\", \"Pizza\"))\n",
    "print(predict_city_cat([\"This is a great restaurant!\"], \"las vegas\", \"Pizza\"))\n",
    "print(predict_city_cat([\"This is a great restaurant!\"], \"phoenix\", \"Chinese\"))\n",
    "print(predict_city_cat([\"This is a great restaurant!\"], \"las vegas\", \"Chinese\"))\n",
    "print(predict_city_cat([\"This is a good review\"], \"las vegas\", \"Chinese\"))\n",
    "print()\n",
    "print(predict_city_cat([\"This is a bad restaurant!\"], \"phoenix\", \"Pizza\"))\n",
    "print(predict_city_cat([\"This is a bad restaurant!\"], \"las vegas\", \"Pizza\"))\n",
    "print(predict_city_cat([\"This is a bad restaurant!\"], \"phoenix\", \"Chinese\"))\n",
    "print(predict_city_cat([\"This is a bad restaurant!\"], \"las vegas\", \"Chinese\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('enc.pkl', 'wb') as enc_file:\n",
    "    pickle.dump(enc, enc_file)\n",
    "\n",
    "with open('vec.pkl', 'wb') as vec_file:\n",
    "    pickle.dump(vectorizer, vec_file)\n",
    "\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(en_final, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pickle.dumps(en_final)\n",
    "p = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_predict(text, city, cat):\n",
    "\n",
    "    text_tf = vectorizer.transform(text)\n",
    "    text_enc = genCity(city)\n",
    "    cat_row = genCat(cat, common_cats)\n",
    "\n",
    "    text_joined = hstack([text_tf, text_enc, cat_row], format=\"csr\")\n",
    "    return p.predict(text_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pickle_predict([\"this is a review\"], \"phoenix\", \"Pizza\"))\n",
    "print(pickle_predict([\"this is a review\"], \"las vegas\", \"Pizza\"))\n",
    "print(pickle_predict([\"this is a review\"], \"phoenix\", \"Chinese\"))\n",
    "print(pickle_predict([\"this is a review\"], \"las vegas\", \"Chinese\"))\n",
    "print()\n",
    "print(pickle_predict([\"This is a great restaurant!\"], \"phoenix\", \"Pizza\"))\n",
    "print(pickle_predict([\"This is a great restaurant!\"], \"las vegas\", \"Pizza\"))\n",
    "print(pickle_predict([\"This is a great restaurant!\"], \"phoenix\", \"Chinese\"))\n",
    "print(pickle_predict([\"This is a great restaurant!\"], \"las vegas\", \"Chinese\"))\n",
    "print(pickle_predict([\"This is a good review\"], \"las vegas\", \"Chinese\"))\n",
    "print()\n",
    "print(pickle_predict([\"This is a bad restaurant!\"], \"phoenix\", \"Pizza\"))\n",
    "print(pickle_predict([\"This is a bad restaurant!\"], \"las vegas\", \"Pizza\"))\n",
    "print(pickle_predict([\"This is a bad restaurant!\"], \"phoenix\", \"Chinese\"))\n",
    "print(pickle_predict([\"This is a bad restaurant!\"], \"las vegas\", \"Chinese\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainJS = pd.SparseDataFrame(X_trainJ)\n",
    "X_trainJS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
