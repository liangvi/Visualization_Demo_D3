{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack, coo_matrix\n",
    "\n",
    "import string\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import nltk\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = pd.read_json('yelp_dataset/business.json', lines=True)\n",
    "#checkin = pd.read_json('yelp_dataset/checkin.json', lines=True)\n",
    "#photo = pd.read_json('yelp_dataset/photo.json', lines=True)\n",
    "#review =  pd.read_json('yelp_dataset/review.json', lines=True)\n",
    "#tip = pd.read_json('yelp_dataset/tip.json', lines=True)\n",
    "##user = pd.read_json('yelp_dataset/user.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2818 E Camino Acequia Drive</td>\n",
       "      <td>{'GoodForKids': 'False'}</td>\n",
       "      <td>1SWheh84yJXfytovILXOAQ</td>\n",
       "      <td>Golf, Active Life</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>33.522143</td>\n",
       "      <td>-112.018481</td>\n",
       "      <td>Arizona Biltmore Golf Club</td>\n",
       "      <td>85016</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30 Eglinton Avenue W</td>\n",
       "      <td>{'RestaurantsReservations': 'True', 'GoodForMe...</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Specialty Food, Restaurants, Dim Sum, Imported...</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>{'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.605499</td>\n",
       "      <td>-79.652289</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>L5R 3E7</td>\n",
       "      <td>128</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10110 Johnston Rd, Ste 15</td>\n",
       "      <td>{'GoodForKids': 'True', 'NoiseLevel': 'u'avera...</td>\n",
       "      <td>gnKjwL_1w79qoiV3IC_xQQ</td>\n",
       "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>{'Monday': '17:30-21:30', 'Wednesday': '17:30-...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.092564</td>\n",
       "      <td>-80.859132</td>\n",
       "      <td>Musashi Japanese Restaurant</td>\n",
       "      <td>28210</td>\n",
       "      <td>170</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15655 W Roosevelt St, Ste 237</td>\n",
       "      <td>None</td>\n",
       "      <td>xvX2CttrVhyG2z1dFg_0xw</td>\n",
       "      <td>Insurance, Financial Services</td>\n",
       "      <td>Goodyear</td>\n",
       "      <td>{'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>33.455613</td>\n",
       "      <td>-112.395596</td>\n",
       "      <td>Farmers Insurance - Paul Lorenz</td>\n",
       "      <td>85338</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4209 Stuart Andrew Blvd, Ste F</td>\n",
       "      <td>{'BusinessAcceptsBitcoin': 'False', 'ByAppoint...</td>\n",
       "      <td>HhyxOkGAM07SRYtlQ4wMFQ</td>\n",
       "      <td>Plumbing, Shopping, Local Services, Home Servi...</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>{'Monday': '7:0-23:0', 'Tuesday': '7:0-23:0', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.190012</td>\n",
       "      <td>-80.887223</td>\n",
       "      <td>Queen City Plumbing</td>\n",
       "      <td>28217</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          address  \\\n",
       "0     2818 E Camino Acequia Drive   \n",
       "1            30 Eglinton Avenue W   \n",
       "2       10110 Johnston Rd, Ste 15   \n",
       "3   15655 W Roosevelt St, Ste 237   \n",
       "4  4209 Stuart Andrew Blvd, Ste F   \n",
       "\n",
       "                                          attributes             business_id  \\\n",
       "0                           {'GoodForKids': 'False'}  1SWheh84yJXfytovILXOAQ   \n",
       "1  {'RestaurantsReservations': 'True', 'GoodForMe...  QXAEGFB4oINsVuTFxEYKFQ   \n",
       "2  {'GoodForKids': 'True', 'NoiseLevel': 'u'avera...  gnKjwL_1w79qoiV3IC_xQQ   \n",
       "3                                               None  xvX2CttrVhyG2z1dFg_0xw   \n",
       "4  {'BusinessAcceptsBitcoin': 'False', 'ByAppoint...  HhyxOkGAM07SRYtlQ4wMFQ   \n",
       "\n",
       "                                          categories         city  \\\n",
       "0                                  Golf, Active Life      Phoenix   \n",
       "1  Specialty Food, Restaurants, Dim Sum, Imported...  Mississauga   \n",
       "2                  Sushi Bars, Restaurants, Japanese    Charlotte   \n",
       "3                      Insurance, Financial Services     Goodyear   \n",
       "4  Plumbing, Shopping, Local Services, Home Servi...    Charlotte   \n",
       "\n",
       "                                               hours  is_open   latitude  \\\n",
       "0                                               None        0  33.522143   \n",
       "1  {'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...        1  43.605499   \n",
       "2  {'Monday': '17:30-21:30', 'Wednesday': '17:30-...        1  35.092564   \n",
       "3  {'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...        1  33.455613   \n",
       "4  {'Monday': '7:0-23:0', 'Tuesday': '7:0-23:0', ...        1  35.190012   \n",
       "\n",
       "    longitude                             name postal_code  review_count  \\\n",
       "0 -112.018481       Arizona Biltmore Golf Club       85016             5   \n",
       "1  -79.652289       Emerald Chinese Restaurant     L5R 3E7           128   \n",
       "2  -80.859132      Musashi Japanese Restaurant       28210           170   \n",
       "3 -112.395596  Farmers Insurance - Paul Lorenz       85338             3   \n",
       "4  -80.887223              Queen City Plumbing       28217             4   \n",
       "\n",
       "   stars state  \n",
       "0    3.0    AZ  \n",
       "1    2.5    ON  \n",
       "2    4.0    NC  \n",
       "3    5.0    AZ  \n",
       "4    4.0    NC  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    \"\"\"\n",
    "    Modified from\n",
    "    http://adataanalyst.com/scikit-learn/countvectorizer-sklearn-example/\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation, and digits \n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    stemmer = EnglishStemmer()\n",
    "   \n",
    "    # Check characters to see if they are in punctuation\n",
    "    clean = [char for char in text if (char not in string.punctuation) \n",
    "            and (not char.isdigit())] \n",
    " \n",
    "    clean = ''.join(clean)\n",
    "    tokens = clean.split()\n",
    "    tokens = [stemmer.stem(c) for c in tokens]\n",
    "    # Join the characters again to form the string.\n",
    "\n",
    "    tokens = ' '.join(tokens)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only look at restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#lv_restaurants\n",
    "restaurants = business['categories'].str.contains('Restaurants', regex=False)\n",
    "restaurants = restaurants.fillna(False)\n",
    "restaurants = business[restaurants]\n",
    "print(restaurants.shape)\n",
    "restaurants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categories_df = pd.Series(restaurants['categories']).str.get_dummies(sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categories_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "totals = categories_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.barh(totals[11:1:-1].keys(),totals[11:1:-1], 0.5,  align='center')\n",
    "plt.title('Top Ten Restaurants Categories')\n",
    "plt.ylabel('Categories')\n",
    "plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nightlife = restaurants['categories'].str.contains('Nightlife', regex=False)\n",
    "nightlife = nightlife.fillna(False)\n",
    "nightlife = restaurants[nightlife]\n",
    "\n",
    "pizza = restaurants['categories'].str.contains('Pizza', regex=False)\n",
    "pizza = pizza.fillna(False)\n",
    "pizza = restaurants[pizza]\n",
    "\n",
    "burgers = restaurants['categories'].str.contains('Burgers', regex=False)\n",
    "burgers = burgers.fillna(False)\n",
    "burgers = restaurants[burgers]\n",
    "burgers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(nightlife['stars'], bins = 10)\n",
    "plt.title('Distribution of Stars for Nightlife')\n",
    "plt.ylabel('Restaurants with Ratings')\n",
    "plt.xlabel('Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(pizza['stars'], bins = 10)\n",
    "plt.title('Distribution of Stars for Pizza')\n",
    "plt.ylabel('Restaurants with Ratings')\n",
    "plt.xlabel('Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(burgers['stars'], bins = 10)\n",
    "plt.title('Distribution of Stars for Burgers')\n",
    "plt.ylabel('Restaurants with Ratings')\n",
    "plt.xlabel('Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(categories_df, \\\n",
    "                                                    restaurants['stars'], test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X_train = pd.Series(X_train).str.get_dummies(sep=', ')\n",
    "#X_test = pd.Series(X_test).str.get_dummies(sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized value to get categories\n",
    "#vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "#categories_count = vectorizer.fit_transform(restaurants['categories']).astype(np.int8)\n",
    "#categories_list = vectorizer.get_feature_names()\n",
    "#categories_df = pd.DataFrame(categories_count.toarray())\n",
    "#categories_df.columns = categories_list\n",
    "#categories_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#check for columns missing from test set\n",
    "#missing_train = list(set(list(X_train)) - set(list(X_test)))\n",
    "#for col in missing_train:\n",
    "#    X_test[col] = 0\n",
    "    \n",
    "#missing_test = list(set(list(X_test)) - set(list(X_train)))\n",
    "#for col in missing_test:\n",
    "#    X_train[col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "y_train_cut = pd.cut(np.array(y_train), 2, labels=[1, 2])\n",
    "y_test_cut = pd.cut(np.array(y_test), 2, labels=[1, 2])\n",
    "np.array(y_train_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, np.array(y_train_cut)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.array(y_test_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neigh.score(X_test, np.array(y_test_cut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy_score(y_test_cut, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reg = linear_model.Ridge(alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "y_pred = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2_score(y_test, y_pred)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regL = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regL.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = regL.predict(X_test)\n",
    "y_pred = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2_score(y_test, y_pred)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##The Whole dataset, but running into memory issues\n",
    "#start = datetime.datetime.now()\n",
    "\n",
    "#iter_review =  pd.read_json('yelp_dataset/review.json', lines=True, chunksize=500)\n",
    "#reviews_df = pd.concat([df[df['business_id'].isin(set(df['business_id']).intersection(set(restaurants['business_id'])))] for df in iter_review])\n",
    "\n",
    "#end = datetime.datetime.now()\n",
    "#elapse = end-start\n",
    "#print(elapse.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews_df_file = open(\"reviews_df_file\",'wb')\n",
    "pickle.dump(reviews_df,reviews_df_file)\n",
    "reviews_df_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews_df_file = open(\"reviews_df_file\",'rb')\n",
    "reviews_df_2 = pickle.load(reviews_df_file)\n",
    "reviews_df_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews_df = pd.DataFrame()\n",
    "start = datetime.datetime.now()\n",
    "for df in pd.read_json('yelp_dataset/review.json', lines=True,  chunksize=1000):\n",
    "    reviews_df = df[df['business_id'].isin(set(df['business_id']).intersection(set(restaurants['business_id'])))]\n",
    "end = datetime.datetime.now()\n",
    "elapse = end-start\n",
    "print(elapse.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews_df.stars.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews_df.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keep the size to 1000 features for size\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "reviews_df.text = reviews_df.text.apply(text_process)\n",
    "vectorizer = TfidfVectorizer(analyzer='word',min_df=10, stop_words = stop_words.ENGLISH_STOP_WORDS, \n",
    "                             ngram_range=(1, 2))\n",
    "text_tfidf = vectorizer.fit_transform(reviews_df.text)\n",
    "text_features = vectorizer.get_feature_names()\n",
    "text_sparse_df = pd.SparseDataFrame(text_tfidf)\n",
    "text_sparse_df.columns = text_features\n",
    "text_sparse_df.fillna(0.0, inplace=True)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "elapse = end-start\n",
    "\n",
    "print(elapse.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews_df.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count_vectorizer = CountVectorizer(analyzer='word',min_df=5, stop_words = stop_words.ENGLISH_STOP_WORDS, \n",
    "                             ngram_range=(1, 1))\n",
    "text_count = count_vectorizer.fit_transform(reviews_df.text)\n",
    "text_count_features = count_vectorizer.get_feature_names()\n",
    "text_count_df = pd.SparseDataFrame(text_count)\n",
    "text_count_df.columns = text_count_features\n",
    "text_count_df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_count_totals = text_count_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.barh(text_count_totals[11::-1].keys(),text_count_totals[11::-1], 0.5,  align='center')\n",
    "plt.title('Top Ten Words in Reviews')\n",
    "plt.ylabel('Words')\n",
    "plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "countn_vectorizer = CountVectorizer(analyzer='word',min_df=5, stop_words = stop_words.ENGLISH_STOP_WORDS, \n",
    "                             ngram_range=(2, 4))\n",
    "text_countn = countn_vectorizer.fit_transform(reviews_df.text)\n",
    "text_countn_features = countn_vectorizer.get_feature_names()\n",
    "text_countn_df = pd.SparseDataFrame(text_countn)\n",
    "text_countn_df.columns = text_countn_features\n",
    "text_countn_df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_countn_totals = text_countn_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.barh(text_countn_totals[11::-1].keys(),text_countn_totals[11::-1], 0.5,  align='center')\n",
    "plt.title('Top Ten Bigram in Reviews')\n",
    "plt.ylabel('Phrases')\n",
    "plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good_reviews = reviews_df[reviews_df.stars >= 4.0]\n",
    "good_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textg_countn = countn_vectorizer.fit_transform(good_reviews.text)\n",
    "textg_countn_features = countn_vectorizer.get_feature_names()\n",
    "textg_countn_df = pd.SparseDataFrame(textg_countn)\n",
    "textg_countn_df.columns = textg_countn_features\n",
    "textg_countn_df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textg_countn_totals = textg_countn_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.barh(textg_countn_totals[7::-1].keys(),textg_countn_totals[7::-1], 0.5,  align='center')\n",
    "plt.title('Top Bigrams in Good Reviews')\n",
    "plt.ylabel('Phrases')\n",
    "plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bad_reviews = reviews_df[reviews_df.stars <= 2.0]\n",
    "bad_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textb_countn = countn_vectorizer.fit_transform(bad_reviews.text)\n",
    "textb_countn_features = countn_vectorizer.get_feature_names()\n",
    "textb_countn_df = pd.SparseDataFrame(textb_countn)\n",
    "textb_countn_df.columns = textb_countn_features\n",
    "textb_countn_df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textb_countn_totals = textb_countn_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.barh(textb_countn_totals[7::-1].keys(),textb_countn_totals[7::-1], 0.5,  align='center')\n",
    "plt.title('Top Bigrams in Bad Reviews')\n",
    "plt.ylabel('Phrases')\n",
    "plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text_sparse_df, \\\n",
    "                                                    reviews_df.stars, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reg = linear_model.Ridge(alpha=.5)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "y_pred = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"MSE:\" + str(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R2:\"+ str(r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ridgereg = linear_model.Ridge()\n",
    "alpha_range = [10, 1, 0.1, 0.01, 0.001]\n",
    "ridge_params = {'alpha': alpha_range}\n",
    "ridge_grid = GridSearchCV(ridgereg, ridge_params, cv=10, scoring='neg_mean_squared_error', n_jobs = 4, return_train_score=True)\n",
    "ridge_grid.fit(X_train, np.ravel(y_train))\n",
    "ridge_results = pd.DataFrame(ridge_grid.cv_results_)\n",
    "ridge_results.sort_values(by='rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regL = linear_model.LinearRegression()\n",
    "regL.fit(X_train, y_train)\n",
    "y_pred_regL = regL.predict(X_test)\n",
    "y_pred_regL = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"MSE:\" + str(mean_squared_error(y_test, y_pred_regL)))\n",
    "print(\"R2:\"+ str(r2_score(y_test, y_pred_regL)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print( \" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_components_range = [10,15,20,25,30]\n",
    "learning_decay_range = [0.5,0.7,0.9]\n",
    "search_params = {'n_components': n_components_range, 'learning_decay': learning_decay_range}\n",
    "\n",
    "lda = LatentDirichletAllocation(max_iter=10, learning_method='online')\n",
    "lda_model = GridSearchCV(lda, param_grid=search_params, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "lda_model.fit(text_count_df)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "elapse = end-start\n",
    "print(elapse.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model\n",
    "best_lda_model = lda_model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", lda_model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", lda_model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(text_count_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Document - Topic Matrix\n",
    "lda_output = best_lda_model.transform(text_count_df)\n",
    "\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_components)]\n",
    "\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(text_count_df))]\n",
    "\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    "    color = 'green' if val > .1 else 'black'\n",
    "    return 'color: {col}'.format(col=color)\n",
    "\n",
    "def make_bold(val):\n",
    "    weight = 700 if val > .1 else 400\n",
    "    return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no_top_words = 2\n",
    "display_topics(best_lda_model, text_count_features, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control for price, location, type of restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pandas-dev/pandas/issues/18152\n",
    "\n",
    "max_records = 1e5\n",
    "df = pd.read_json('yelp_dataset/review.json', lines=True, chunksize=max_records)\n",
    "reviews = pd.DataFrame() # Initialize the dataframe\n",
    "try:\n",
    "   for df_chunk in df:\n",
    "       reviews = pd.concat([reviews, df_chunk])\n",
    "except ValueError:\n",
    "       print ('\\nSome messages in the file cannot be parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6685900, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>6</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>0</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>3</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>0</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>0</td>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>7</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  ujmEBvifdJM6h6RLv4wQIg     0 2013-05-07 04:34:36      1   \n",
       "1  NZnhc2sEQy3RmzKTZnqtwQ     0 2017-01-14 21:30:33      0   \n",
       "2  WTqjgwHlXbSFevF32_DJVw     0 2016-11-09 20:09:03      0   \n",
       "3  ikCg8xy5JIg_NGPx-MSIDA     0 2018-01-09 20:56:38      0   \n",
       "4  b1b1eb3uo-w561D0ZfCEiQ     0 2018-01-30 23:07:38      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q      1   \n",
       "1  GJXCdrto3ASJOqKeVWPi6Q      5   \n",
       "2  2TzJjDVDEuAW6MR5Vuc1ug      5   \n",
       "3  yi0R0Ugj_xUx_Nek0-_Qig      5   \n",
       "4  11a8sVPMUFtaC7_ABRkmtw      1   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  Total bill for this horrible service? Over $8G...       6   \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...       0   \n",
       "2  I have to say that this office really has it t...       3   \n",
       "3  Went in for a lunch. Steak sandwich was delici...       0   \n",
       "4  Today was my second out of three sessions I ha...       7   \n",
       "\n",
       "                  user_id  \n",
       "0  hG7b0MtEbXx5QzbzE6C_VA  \n",
       "1  yXQM5uF2jS6es16SJzNHfg  \n",
       "2  n6-Gk65cPZL6Uz8qRm3NYw  \n",
       "3  dacAIZ6fTM6mqwW5uxkskg  \n",
       "4  ssoyf2_x0EQMed6fgHeMyQ  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = reviews.join(business, lsuffix='_r', rsuffix='_b', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192609, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id_r</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars_r</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>address</th>\n",
       "      <th>...</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars_b</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>6</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>2818 E Camino Acequia Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>33.522143</td>\n",
       "      <td>-112.018481</td>\n",
       "      <td>Arizona Biltmore Golf Club</td>\n",
       "      <td>85016</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>30 Eglinton Avenue W</td>\n",
       "      <td>...</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>{'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.605499</td>\n",
       "      <td>-79.652289</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>L5R 3E7</td>\n",
       "      <td>128</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>0</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>3</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>10110 Johnston Rd, Ste 15</td>\n",
       "      <td>...</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>{'Monday': '17:30-21:30', 'Wednesday': '17:30-...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.092564</td>\n",
       "      <td>-80.859132</td>\n",
       "      <td>Musashi Japanese Restaurant</td>\n",
       "      <td>28210</td>\n",
       "      <td>170</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>5</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>0</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "      <td>15655 W Roosevelt St, Ste 237</td>\n",
       "      <td>...</td>\n",
       "      <td>Goodyear</td>\n",
       "      <td>{'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>33.455613</td>\n",
       "      <td>-112.395596</td>\n",
       "      <td>Farmers Insurance - Paul Lorenz</td>\n",
       "      <td>85338</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>0</td>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>1</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>7</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "      <td>4209 Stuart Andrew Blvd, Ste F</td>\n",
       "      <td>...</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>{'Monday': '7:0-23:0', 'Tuesday': '7:0-23:0', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.190012</td>\n",
       "      <td>-80.887223</td>\n",
       "      <td>Queen City Plumbing</td>\n",
       "      <td>28217</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            business_id_r  cool                date  funny  \\\n",
       "0  ujmEBvifdJM6h6RLv4wQIg     0 2013-05-07 04:34:36      1   \n",
       "1  NZnhc2sEQy3RmzKTZnqtwQ     0 2017-01-14 21:30:33      0   \n",
       "2  WTqjgwHlXbSFevF32_DJVw     0 2016-11-09 20:09:03      0   \n",
       "3  ikCg8xy5JIg_NGPx-MSIDA     0 2018-01-09 20:56:38      0   \n",
       "4  b1b1eb3uo-w561D0ZfCEiQ     0 2018-01-30 23:07:38      0   \n",
       "\n",
       "                review_id  stars_r  \\\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q        1   \n",
       "1  GJXCdrto3ASJOqKeVWPi6Q        5   \n",
       "2  2TzJjDVDEuAW6MR5Vuc1ug        5   \n",
       "3  yi0R0Ugj_xUx_Nek0-_Qig        5   \n",
       "4  11a8sVPMUFtaC7_ABRkmtw        1   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  Total bill for this horrible service? Over $8G...       6   \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...       0   \n",
       "2  I have to say that this office really has it t...       3   \n",
       "3  Went in for a lunch. Steak sandwich was delici...       0   \n",
       "4  Today was my second out of three sessions I ha...       7   \n",
       "\n",
       "                  user_id                         address  ...          city  \\\n",
       "0  hG7b0MtEbXx5QzbzE6C_VA     2818 E Camino Acequia Drive  ...       Phoenix   \n",
       "1  yXQM5uF2jS6es16SJzNHfg            30 Eglinton Avenue W  ...   Mississauga   \n",
       "2  n6-Gk65cPZL6Uz8qRm3NYw       10110 Johnston Rd, Ste 15  ...     Charlotte   \n",
       "3  dacAIZ6fTM6mqwW5uxkskg   15655 W Roosevelt St, Ste 237  ...      Goodyear   \n",
       "4  ssoyf2_x0EQMed6fgHeMyQ  4209 Stuart Andrew Blvd, Ste F  ...     Charlotte   \n",
       "\n",
       "                                               hours is_open   latitude  \\\n",
       "0                                               None       0  33.522143   \n",
       "1  {'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...       1  43.605499   \n",
       "2  {'Monday': '17:30-21:30', 'Wednesday': '17:30-...       1  35.092564   \n",
       "3  {'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...       1  33.455613   \n",
       "4  {'Monday': '7:0-23:0', 'Tuesday': '7:0-23:0', ...       1  35.190012   \n",
       "\n",
       "    longitude                             name  postal_code  review_count  \\\n",
       "0 -112.018481       Arizona Biltmore Golf Club        85016             5   \n",
       "1  -79.652289       Emerald Chinese Restaurant      L5R 3E7           128   \n",
       "2  -80.859132      Musashi Japanese Restaurant        28210           170   \n",
       "3 -112.395596  Farmers Insurance - Paul Lorenz        85338             3   \n",
       "4  -80.887223              Queen City Plumbing        28217             4   \n",
       "\n",
       "  stars_b state  \n",
       "0     3.0    AZ  \n",
       "1     2.5    ON  \n",
       "2     4.0    NC  \n",
       "3     5.0    AZ  \n",
       "4     4.0    NC  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(joined.shape)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59371, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id_r</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars_r</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>address</th>\n",
       "      <th>...</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars_b</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>5</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>30 Eglinton Avenue W</td>\n",
       "      <td>...</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>{'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.605499</td>\n",
       "      <td>-79.652289</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>L5R 3E7</td>\n",
       "      <td>128</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>0</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>5</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>3</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>10110 Johnston Rd, Ste 15</td>\n",
       "      <td>...</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>{'Monday': '17:30-21:30', 'Wednesday': '17:30-...</td>\n",
       "      <td>1</td>\n",
       "      <td>35.092564</td>\n",
       "      <td>-80.859132</td>\n",
       "      <td>Musashi Japanese Restaurant</td>\n",
       "      <td>28210</td>\n",
       "      <td>170</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mRUVMJkUGxrByzMQ2MuOpA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-15 23:27:08</td>\n",
       "      <td>1</td>\n",
       "      <td>-I5umRTkhw15RqpKMl_o1Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Walked in around 4 on a Friday afternoon, we s...</td>\n",
       "      <td>0</td>\n",
       "      <td>-mA3-1mN4JIEkqOtdbNXCQ</td>\n",
       "      <td>2450 E Indian School Rd</td>\n",
       "      <td>...</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>{'Monday': '7:0-0:0', 'Tuesday': '7:0-0:0', 'W...</td>\n",
       "      <td>1</td>\n",
       "      <td>33.495194</td>\n",
       "      <td>-112.028588</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>85016</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LUN6swQYa4xJKaM_UEUOEw</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-27 20:25:26</td>\n",
       "      <td>0</td>\n",
       "      <td>qlXw1JQ0UodW7qrmVgwCXw</td>\n",
       "      <td>4</td>\n",
       "      <td>Michael from Red Carpet VIP is amazing ! I rea...</td>\n",
       "      <td>0</td>\n",
       "      <td>bAhqAPoWaZYcyYi7bs024Q</td>\n",
       "      <td>5981 Andrews Rd</td>\n",
       "      <td>...</td>\n",
       "      <td>Mentor-on-the-Lake</td>\n",
       "      <td>{'Monday': '10:0-0:0', 'Tuesday': '10:0-0:0', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.708520</td>\n",
       "      <td>-81.359556</td>\n",
       "      <td>Marco's Pizza</td>\n",
       "      <td>44060</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cHdJXLlKNWixBXpDwEGb_A</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-04-01 16:30:00</td>\n",
       "      <td>7</td>\n",
       "      <td>6BnQwlxRn7ZuWdzninM9sQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I love chinese food and I love mexican food. W...</td>\n",
       "      <td>1</td>\n",
       "      <td>JSrP-dUmLlwZiI7Dp3PQ2A</td>\n",
       "      <td>1775 E Tropicana Ave, Ste 29</td>\n",
       "      <td>...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>36.100016</td>\n",
       "      <td>-115.128529</td>\n",
       "      <td>Carluccio's Tivoli Gardens</td>\n",
       "      <td>89119</td>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             business_id_r  cool                date  funny  \\\n",
       "1   NZnhc2sEQy3RmzKTZnqtwQ     0 2017-01-14 21:30:33      0   \n",
       "2   WTqjgwHlXbSFevF32_DJVw     0 2016-11-09 20:09:03      0   \n",
       "11  mRUVMJkUGxrByzMQ2MuOpA     0 2017-12-15 23:27:08      1   \n",
       "13  LUN6swQYa4xJKaM_UEUOEw     0 2018-04-27 20:25:26      0   \n",
       "17  cHdJXLlKNWixBXpDwEGb_A     1 2015-04-01 16:30:00      7   \n",
       "\n",
       "                 review_id  stars_r  \\\n",
       "1   GJXCdrto3ASJOqKeVWPi6Q        5   \n",
       "2   2TzJjDVDEuAW6MR5Vuc1ug        5   \n",
       "11  -I5umRTkhw15RqpKMl_o1Q        1   \n",
       "13  qlXw1JQ0UodW7qrmVgwCXw        4   \n",
       "17  6BnQwlxRn7ZuWdzninM9sQ        3   \n",
       "\n",
       "                                                 text  useful  \\\n",
       "1   I *adore* Travis at the Hard Rock's new Kelly ...       0   \n",
       "2   I have to say that this office really has it t...       3   \n",
       "11  Walked in around 4 on a Friday afternoon, we s...       0   \n",
       "13  Michael from Red Carpet VIP is amazing ! I rea...       0   \n",
       "17  I love chinese food and I love mexican food. W...       1   \n",
       "\n",
       "                   user_id                       address  ...   \\\n",
       "1   yXQM5uF2jS6es16SJzNHfg          30 Eglinton Avenue W  ...    \n",
       "2   n6-Gk65cPZL6Uz8qRm3NYw     10110 Johnston Rd, Ste 15  ...    \n",
       "11  -mA3-1mN4JIEkqOtdbNXCQ       2450 E Indian School Rd  ...    \n",
       "13  bAhqAPoWaZYcyYi7bs024Q               5981 Andrews Rd  ...    \n",
       "17  JSrP-dUmLlwZiI7Dp3PQ2A  1775 E Tropicana Ave, Ste 29  ...    \n",
       "\n",
       "                  city                                              hours  \\\n",
       "1          Mississauga  {'Monday': '9:0-0:0', 'Tuesday': '9:0-0:0', 'W...   \n",
       "2            Charlotte  {'Monday': '17:30-21:30', 'Wednesday': '17:30-...   \n",
       "11             Phoenix  {'Monday': '7:0-0:0', 'Tuesday': '7:0-0:0', 'W...   \n",
       "13  Mentor-on-the-Lake  {'Monday': '10:0-0:0', 'Tuesday': '10:0-0:0', ...   \n",
       "17           Las Vegas                                               None   \n",
       "\n",
       "   is_open   latitude   longitude                         name  postal_code  \\\n",
       "1        1  43.605499  -79.652289   Emerald Chinese Restaurant      L5R 3E7   \n",
       "2        1  35.092564  -80.859132  Musashi Japanese Restaurant        28210   \n",
       "11       1  33.495194 -112.028588                    Taco Bell        85016   \n",
       "13       1  41.708520  -81.359556                Marco's Pizza        44060   \n",
       "17       0  36.100016 -115.128529   Carluccio's Tivoli Gardens        89119   \n",
       "\n",
       "    review_count stars_b state  \n",
       "1            128     2.5    ON  \n",
       "2            170     4.0    NC  \n",
       "11            18     3.0    AZ  \n",
       "13            16     4.0    OH  \n",
       "17            40     4.0    NV  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = joined['categories'].str.contains('Restaurants', regex=False)\n",
    "temp = temp.fillna(False)\n",
    "joined = joined[temp]\n",
    "print(joined.shape)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joined_lv = joined[joined['city']==\"Las Vegas\"]\n",
    "joined_lv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#lv_restaurants\n",
    "restaurants = joined_lv['categories'].str.contains('Restaurants', regex=False)\n",
    "restaurants = restaurants.fillna(False)\n",
    "restaurants = joined_lv[restaurants]\n",
    "print(restaurants.shape)\n",
    "restaurants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restaurants.name.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categories_df = pd.Series(restaurants['categories']).str.get_dummies(sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categories_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "totals = categories_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.barh(totals[11:1:-1].keys(),totals[11:1:-1], 0.5,  align='center')\n",
    "plt.title('Top Ten Restaurants Categories')\n",
    "plt.ylabel('Categories')\n",
    "plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only look at nightlife in Las Vegas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#lv_restaurants\n",
    "nightlife = joined_lv['categories'].str.contains('Nightlife', regex=False)\n",
    "nightlife = nightlife.fillna(False)\n",
    "nightlife = joined_lv[nightlife]\n",
    "print(nightlife.shape)\n",
    "nightlife.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "nightlife.text = nightlife.text.apply(text_process)\n",
    "nightlife.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keep the size to 1000 features for size\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "nightlife.text = nightlife.text.apply(text_process)\n",
    "vectorizer = TfidfVectorizer(analyzer='word',min_df=10, stop_words = stop_words.ENGLISH_STOP_WORDS, \n",
    "                             ngram_range=(1, 2))\n",
    "text_tfidf = vectorizer.fit_transform(nightlife.text)\n",
    "text_features = vectorizer.get_feature_names()\n",
    "text_sparse_df = pd.SparseDataFrame(text_tfidf)\n",
    "text_sparse_df.columns = text_features\n",
    "text_sparse_df.fillna(0.0, inplace=True)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "elapse = end-start\n",
    "\n",
    "print(elapse.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "nightlife.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#https://www.geeksforgeeks.org/part-speech-tagging-stop-words-using-nltk-python/\n",
    "CC coordinating conjunction\n",
    "CD cardinal digit\n",
    "DT determiner\n",
    "EX existential there (like: â€œthere isâ€ â€¦ think of it like â€œthere existsâ€)\n",
    "FW foreign word\n",
    "IN preposition/subordinating conjunction\n",
    "JJ adjective â€˜bigâ€™\n",
    "JJR adjective, comparative â€˜biggerâ€™\n",
    "JJS adjective, superlative â€˜biggestâ€™\n",
    "LS list marker 1)\n",
    "MD modal could, will\n",
    "NN noun, singular â€˜deskâ€™\n",
    "NNS noun plural â€˜desksâ€™\n",
    "NNP proper noun, singular â€˜Harrisonâ€™\n",
    "NNPS proper noun, plural â€˜Americansâ€™\n",
    "PDT predeterminer â€˜all the kidsâ€™\n",
    "POS possessive ending parentâ€˜s\n",
    "PRP personal pronoun I, he, she\n",
    "PRP$ possessive pronoun my, his, hers\n",
    "RB adverb very, silently,\n",
    "RBR adverb, comparative better\n",
    "RBS adverb, superlative best\n",
    "RP particle give up\n",
    "TO to go â€˜toâ€˜ the store.\n",
    "UH interjection errrrrrrrm\n",
    "VB verb, base form take\n",
    "VBD verb, past tense took\n",
    "VBG verb, gerund/present participle taking\n",
    "VBN verb, past participle taken\n",
    "VBP verb, sing. present, non-3d take\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "WDT wh-determiner which\n",
    "WP wh-pronoun who, what\n",
    "WP$ possessive wh-pronoun whose\n",
    "WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.w3schools.com/python/ref_string_join.asp\n",
    "def tokenize(string):\n",
    "    d = []\n",
    "    tokens = nltk.word_tokenize(string)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    for x in tags:\n",
    "        if x[1] == \"NN\" or x[1] == \"NNS\" or x[1] == \"NNP\" or x[1] == \"NNPS\":\n",
    "            d.append(x[0])\n",
    "    d = \" \".join(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize(\"This is a sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "nightlife['text'] = nightlife['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nightlife[\"text\"].str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count_vectorizer = CountVectorizer(analyzer='word',min_df=5, stop_words = stop_words.ENGLISH_STOP_WORDS, \n",
    "                             ngram_range=(1, 1))\n",
    "text_count = count_vectorizer.fit_transform(nightlife.text)\n",
    "text_count_features = count_vectorizer.get_feature_names()\n",
    "text_count_df = pd.SparseDataFrame(text_count)\n",
    "text_count_df.columns = text_count_features\n",
    "text_count_df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_count_totals = text_count_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.barh(text_count_totals[11::-1].keys(),text_count_totals[11::-1], 0.5,  align='center')\n",
    "plt.title('Top Ten Words in Reviews')\n",
    "plt.ylabel('Words')\n",
    "plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "countn_vectorizer = CountVectorizer(analyzer='word',min_df=5, stop_words = stop_words.ENGLISH_STOP_WORDS, \n",
    "                             ngram_range=(2, 4))\n",
    "text_countn = countn_vectorizer.fit_transform(nightlife.text)\n",
    "text_countn_features = countn_vectorizer.get_feature_names()\n",
    "text_countn_df = pd.SparseDataFrame(text_countn)\n",
    "text_countn_df.columns = text_countn_features\n",
    "text_countn_df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_countn_totals = text_countn_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.barh(text_countn_totals[11::-1].keys(),text_countn_totals[11::-1], 0.5,  align='center')\n",
    "plt.title('Top Ten Bigram in Reviews')\n",
    "plt.ylabel('Phrases')\n",
    "plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good_reviews = nightlife[nightlife.stars_r >= 4.0]\n",
    "good_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textg_countn = countn_vectorizer.fit_transform(good_reviews.text)\n",
    "textg_countn_features = countn_vectorizer.get_feature_names()\n",
    "textg_countn_df = pd.SparseDataFrame(textg_countn)\n",
    "textg_countn_df.columns = textg_countn_features\n",
    "textg_countn_df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textg_countn_totals = textg_countn_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.barh(textg_countn_totals[7::-1].keys(),textg_countn_totals[7::-1], 0.5,  align='center')\n",
    "plt.title('Top Bigrams in Good Reviews')\n",
    "plt.ylabel('Phrases')\n",
    "plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bad_reviews = nightlife[nightlife.stars_r <= 2.0]\n",
    "bad_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textb_countn = countn_vectorizer.fit_transform(bad_reviews.text)\n",
    "textb_countn_features = countn_vectorizer.get_feature_names()\n",
    "textb_countn_df = pd.SparseDataFrame(textb_countn)\n",
    "textb_countn_df.columns = textb_countn_features\n",
    "textb_countn_df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textb_countn_totals = textb_countn_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.barh(textb_countn_totals[7::-1].keys(),textb_countn_totals[7::-1], 0.5,  align='center')\n",
    "plt.title('Top Bigrams in Bad Reviews')\n",
    "plt.ylabel('Phrases')\n",
    "plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_and_loc(cat, loc):\n",
    "    #filter location\n",
    "    joined_loc = joined[joined['city']==loc]\n",
    "    \n",
    "    #filter restaurants\n",
    "    restaurants = joined_loc['categories'].str.contains('Restaurants', regex=False)\n",
    "    restaurants = restaurants.fillna(False)\n",
    "    restaurants = joined_loc[restaurants]\n",
    "    \n",
    "    #filter category\n",
    "    category = joined_loc['categories'].str.contains(cat, regex=False)\n",
    "    category = category.fillna(False)\n",
    "    category = joined_loc[category]\n",
    "    \n",
    "    #text manipulation\n",
    "    category.text = category.text.apply(text_process)\n",
    "\n",
    "    ## keep the size to 1000 features for size\n",
    "\n",
    "    category.text = category.text.apply(text_process)\n",
    "    vectorizer = TfidfVectorizer(analyzer='word',min_df=10, stop_words = stop_words.ENGLISH_STOP_WORDS, \n",
    "                                 ngram_range=(1, 2))\n",
    "    text_tfidf = vectorizer.fit_transform(category.text)\n",
    "    text_features = vectorizer.get_feature_names()\n",
    "    text_sparse_df = pd.SparseDataFrame(text_tfidf)\n",
    "    text_sparse_df.columns = text_features\n",
    "    text_sparse_df.fillna(0.0, inplace=True)\n",
    "    \n",
    "    category.text = category.text.apply(tokenize)\n",
    "    \n",
    "    count_vectorizer = CountVectorizer(analyzer='word',min_df=5, stop_words = stop_words.ENGLISH_STOP_WORDS, \n",
    "                             ngram_range=(1, 1))\n",
    "    text_count = count_vectorizer.fit_transform(category.text)\n",
    "    text_count_features = count_vectorizer.get_feature_names()\n",
    "    text_count_df = pd.SparseDataFrame(text_count)\n",
    "    text_count_df.columns = text_count_features\n",
    "    text_count_df.fillna(0.0, inplace=True)\n",
    "\n",
    "    text_count_totals = text_count_df.sum().sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(25,20))\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.barh(text_count_totals[11::-1].keys(),text_count_totals[11::-1], 0.5,  align='center')\n",
    "    plt.title('Top Ten Words in Reviews')\n",
    "    plt.ylabel('Words')\n",
    "    plt.xlabel('Frequency')\n",
    "    \n",
    "    countn_vectorizer = CountVectorizer(analyzer='word',min_df=5, stop_words = stop_words.ENGLISH_STOP_WORDS, \n",
    "                             ngram_range=(2, 4))\n",
    "    text_countn = countn_vectorizer.fit_transform(category.text)\n",
    "    text_countn_features = countn_vectorizer.get_feature_names()\n",
    "    text_countn_df = pd.SparseDataFrame(text_countn)\n",
    "    text_countn_df.columns = text_countn_features\n",
    "    text_countn_df.fillna(0.0, inplace=True)\n",
    "    \n",
    "    text_countn_totals = text_countn_df.sum().sort_values(ascending=False)\n",
    "    \n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.barh(text_countn_totals[11::-1].keys(),text_countn_totals[11::-1], 0.5,  align='center')\n",
    "    plt.title('Top Ten Bigram in Reviews')\n",
    "    plt.ylabel('Phrases')\n",
    "    plt.xlabel('Frequency')\n",
    "    \n",
    "    good_reviews = category[category.stars_r >= 4.0]\n",
    "    textg_countn = countn_vectorizer.fit_transform(good_reviews.text)\n",
    "    textg_countn_features = countn_vectorizer.get_feature_names()\n",
    "    textg_countn_df = pd.SparseDataFrame(textg_countn)\n",
    "    textg_countn_df.columns = textg_countn_features\n",
    "    textg_countn_df.fillna(0.0, inplace=True)\n",
    "    textg_countn_totals = textg_countn_df.sum().sort_values(ascending=False)\n",
    "    \n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.barh(textg_countn_totals[7::-1].keys(),textg_countn_totals[7::-1], 0.5,  align='center')\n",
    "    plt.title('Top Bigrams in Good Reviews')\n",
    "    plt.ylabel('Phrases')\n",
    "    plt.xlabel('Frequency')\n",
    "    \n",
    "    bad_reviews = category[category.stars_r <= 2.0]\n",
    "    textb_countn = countn_vectorizer.fit_transform(bad_reviews.text)\n",
    "    textb_countn_features = countn_vectorizer.get_feature_names()\n",
    "    textb_countn_df = pd.SparseDataFrame(textb_countn)\n",
    "    textb_countn_df.columns = textb_countn_features\n",
    "    textb_countn_df.fillna(0.0, inplace=True)\n",
    "    textb_countn_totals = textb_countn_df.sum().sort_values(ascending=False)\n",
    "    \n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.barh(textb_countn_totals[7::-1].keys(),textb_countn_totals[7::-1], 0.5,  align='center')\n",
    "    plt.title('Top Bigrams in Bad Reviews')\n",
    "    plt.ylabel('Phrases')\n",
    "    plt.xlabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_and_loc(\"Nightlife\", \"Las Vegas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_and_loc(\"Mexican\", \"Las Vegas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_and_loc(\"Breakfast & Brunch\", \"Las Vegas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_and_loc(\"Mexican\", \"Phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_and_loc(\"Sushi\", \"Toronto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_and_loc(\"Sushi\", \"Las Vegas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_and_loc(\"Pizza\", \"Toronto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_and_loc(\"Pizza\", \"Las Vegas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = joined[['text', 'city', 'categories']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp, joined['stars_r'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<47496x982 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2530959 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = X_train['text']\n",
    "vectorizer = TfidfVectorizer(min_df = 0.01)\n",
    "\n",
    "vectorizer.fit(corpus)\n",
    "\n",
    "tf_train = vectorizer.transform(corpus)\n",
    "tf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11875x982 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 636571 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test data\n",
    "test_corpus = X_test['text']\n",
    "tf_test = vectorizer.transform(test_corpus)\n",
    "tf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf_train = pd.SparseDataFrame(tf_train.toarray(),columns=vectorizer.get_feature_names(),index=X_trainC.index)\n",
    "tf_test = pd.SparseDataFrame(tf_test.toarray(),columns=vectorizer.get_feature_names(),index=X_testC.index)\n",
    "tf_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45640</th>\n",
       "      <td>Delicious original and unique. Great atmospher...</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, Food, Cafeteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9017</th>\n",
       "      <td>Like many Yelpers, I was eager to try this new...</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Steakhouses, Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48483</th>\n",
       "      <td>Saturday was a ladies night out. So as I meet ...</td>\n",
       "      <td>North York</td>\n",
       "      <td>ON</td>\n",
       "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102691</th>\n",
       "      <td>This place is great!! Good food, neat atmosphe...</td>\n",
       "      <td>MontrÃ©al</td>\n",
       "      <td>QC</td>\n",
       "      <td>Vegetarian, Mediterranean, Restaurants, Falafel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>Sunday dinner was okay, not bad but not good. ...</td>\n",
       "      <td>Brampton</td>\n",
       "      <td>ON</td>\n",
       "      <td>Caterers, Nightlife, Caribbean, Restaurants, E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text        city state  \\\n",
       "45640   Delicious original and unique. Great atmospher...       Tempe    AZ   \n",
       "9017    Like many Yelpers, I was eager to try this new...       Tempe    AZ   \n",
       "48483   Saturday was a ladies night out. So as I meet ...  North York    ON   \n",
       "102691  This place is great!! Good food, neat atmosphe...    MontrÃ©al    QC   \n",
       "8680    Sunday dinner was okay, not bad but not good. ...    Brampton    ON   \n",
       "\n",
       "                                               categories  \n",
       "45640                        Restaurants, Food, Cafeteria  \n",
       "9017                             Steakhouses, Restaurants  \n",
       "48483                   Sushi Bars, Restaurants, Japanese  \n",
       "102691    Vegetarian, Mediterranean, Restaurants, Falafel  \n",
       "8680    Caterers, Nightlife, Caribbean, Restaurants, E...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cats = ['Nightlife', 'Pizza', 'Burger', 'Chinese', 'Steak', 'Sandwiches', 'Fast Food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "      <th>Nightlife</th>\n",
       "      <th>Pizza</th>\n",
       "      <th>Burger</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Steak</th>\n",
       "      <th>Sandwiches</th>\n",
       "      <th>Fast Food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45640</th>\n",
       "      <td>Delicious original and unique. Great atmospher...</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, Food, Cafeteria</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9017</th>\n",
       "      <td>Like many Yelpers, I was eager to try this new...</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Steakhouses, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48483</th>\n",
       "      <td>Saturday was a ladies night out. So as I meet ...</td>\n",
       "      <td>North York</td>\n",
       "      <td>ON</td>\n",
       "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102691</th>\n",
       "      <td>This place is great!! Good food, neat atmosphe...</td>\n",
       "      <td>MontrÃ©al</td>\n",
       "      <td>QC</td>\n",
       "      <td>Vegetarian, Mediterranean, Restaurants, Falafel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>Sunday dinner was okay, not bad but not good. ...</td>\n",
       "      <td>Brampton</td>\n",
       "      <td>ON</td>\n",
       "      <td>Caterers, Nightlife, Caribbean, Restaurants, E...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text        city state  \\\n",
       "45640   Delicious original and unique. Great atmospher...       Tempe    AZ   \n",
       "9017    Like many Yelpers, I was eager to try this new...       Tempe    AZ   \n",
       "48483   Saturday was a ladies night out. So as I meet ...  North York    ON   \n",
       "102691  This place is great!! Good food, neat atmosphe...    MontrÃ©al    QC   \n",
       "8680    Sunday dinner was okay, not bad but not good. ...    Brampton    ON   \n",
       "\n",
       "                                               categories  Nightlife  Pizza  \\\n",
       "45640                        Restaurants, Food, Cafeteria          0      0   \n",
       "9017                             Steakhouses, Restaurants          0      0   \n",
       "48483                   Sushi Bars, Restaurants, Japanese          0      0   \n",
       "102691    Vegetarian, Mediterranean, Restaurants, Falafel          0      0   \n",
       "8680    Caterers, Nightlife, Caribbean, Restaurants, E...          0      0   \n",
       "\n",
       "        Burger  Chinese  Steak  Sandwiches  Fast Food  \n",
       "45640        0        0      0           0          0  \n",
       "9017         0        0      0           0          0  \n",
       "48483        0        0      0           0          0  \n",
       "102691       0        0      0           0          0  \n",
       "8680         0        0      0           0          0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cat in common_cats:\n",
    "    cats[cat] = 0\n",
    "    cats[cat] = 0\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>categories</th>\n",
       "      <th>Nightlife</th>\n",
       "      <th>Pizza</th>\n",
       "      <th>Burger</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Steak</th>\n",
       "      <th>Sandwiches</th>\n",
       "      <th>Fast Food</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45640</th>\n",
       "      <td>Delicious original and unique. Great atmospher...</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, Food, Cafeteria</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9017</th>\n",
       "      <td>Like many Yelpers, I was eager to try this new...</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Steakhouses, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48483</th>\n",
       "      <td>Saturday was a ladies night out. So as I meet ...</td>\n",
       "      <td>North York</td>\n",
       "      <td>ON</td>\n",
       "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102691</th>\n",
       "      <td>This place is great!! Good food, neat atmosphe...</td>\n",
       "      <td>MontrÃ©al</td>\n",
       "      <td>QC</td>\n",
       "      <td>Vegetarian, Mediterranean, Restaurants, Falafel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>Sunday dinner was okay, not bad but not good. ...</td>\n",
       "      <td>Brampton</td>\n",
       "      <td>ON</td>\n",
       "      <td>Caterers, Nightlife, Caribbean, Restaurants, E...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48319</th>\n",
       "      <td>Had some extra time to spare at Pearson so I p...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Steakhouses, Bars, Nightlife, Restaurants, Ame...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86369</th>\n",
       "      <td>I've been here twice so far, and the experienc...</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, American (New), Burgers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48730</th>\n",
       "      <td>Ow on the other hand this place really not tha...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>American (Traditional), Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72702</th>\n",
       "      <td>Hands down our the best experience of the whol...</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>Salad, Sandwiches, Fast Food, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112372</th>\n",
       "      <td>My favorite local Italian restaurant in Hender...</td>\n",
       "      <td>Gastonia</td>\n",
       "      <td>NC</td>\n",
       "      <td>Southern, Restaurants, Breakfast &amp; Brunch, Mex...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60421</th>\n",
       "      <td>The service deserves 5 stars. We went early Ju...</td>\n",
       "      <td>North Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Restaurants, Mexican</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29028</th>\n",
       "      <td>Awesome food and Service. Love how they all wo...</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>NC</td>\n",
       "      <td>Diners, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116177</th>\n",
       "      <td>Yay!!! I second the first review!  Blimpie's i...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Delis, Sandwiches, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87525</th>\n",
       "      <td>Incredible job! I've been going to OohLaLash f...</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Food, Caterers, Restaurants, Event Planning &amp; ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145520</th>\n",
       "      <td>This location accepts Starbucks gift cards as ...</td>\n",
       "      <td>Madison</td>\n",
       "      <td>WI</td>\n",
       "      <td>Bars, Burgers, Music Venues, American (New), A...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144674</th>\n",
       "      <td>Excellent restaurant hands down  This restaura...</td>\n",
       "      <td>Scarborough</td>\n",
       "      <td>ON</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63485</th>\n",
       "      <td>I used to come here as a kid, because my paren...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>Fast Food, Restaurants, Chicken Wings, Seafood</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17702</th>\n",
       "      <td>This was our first time at Block and Grinder a...</td>\n",
       "      <td>MontrÃ©al</td>\n",
       "      <td>QC</td>\n",
       "      <td>Irish, Restaurants, Irish Pub, Nightlife, Pubs...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76437</th>\n",
       "      <td>Quick and efficient for a burrito.  Had a bean...</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>ON</td>\n",
       "      <td>Asian Fusion, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186236</th>\n",
       "      <td>Huge portions at decent prices. Love the fact ...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Buffets, Restaurants, Japanese, Salad, Korean,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162905</th>\n",
       "      <td>Menchies.... I love it. I have an obsession wi...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Casinos, Event Planning &amp; Services, Restaurant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56146</th>\n",
       "      <td>Best steak house in Charlotte! Service is grea...</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "      <td>Dive Bars, Restaurants, Bars, Nightlife, Ameri...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173742</th>\n",
       "      <td>You know a restaurant is phenomenal when the f...</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>AB</td>\n",
       "      <td>Pubs, Nightlife, American (New), Bars, Restaur...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153097</th>\n",
       "      <td>The downsides: overpriced food, limited menu, ...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>Mexican, Fast Food, Vegan, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145602</th>\n",
       "      <td>The crab cakes were awesome as was the wine! M...</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Mexican, Convenience Stores, Restaurants, Ital...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133626</th>\n",
       "      <td>A pleasure to work with these guys. They did a...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Food, Restaurants, Fast Food, Chicken Wings, C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115891</th>\n",
       "      <td>I have to give a shout out to Tori who wrote m...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>Restaurants, Mexican</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27281</th>\n",
       "      <td>Just moved to Brentwood and right down the roa...</td>\n",
       "      <td>Chesterland</td>\n",
       "      <td>OH</td>\n",
       "      <td>Chinese, Soup, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31916</th>\n",
       "      <td>I would like to share my incredible experience...</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>AB</td>\n",
       "      <td>Indian, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141735</th>\n",
       "      <td>Ask for your frappes to be twice blended! Elim...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Hot Dogs, Ice Cream &amp; Frozen Yogurt, Fast Food...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134660</th>\n",
       "      <td>Have played several times this year.  Conditio...</td>\n",
       "      <td>Peoria</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, Do-It-Yourself Food, Food</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89265</th>\n",
       "      <td>Loved this place but they had a fire and is no...</td>\n",
       "      <td>Painesville</td>\n",
       "      <td>OH</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch, American (Tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21197</th>\n",
       "      <td>One of my favorite restaurants in the area. Fo...</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>Italian, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93215</th>\n",
       "      <td>Great experience! Service, food and atmosphere...</td>\n",
       "      <td>MontrÃ©al</td>\n",
       "      <td>QC</td>\n",
       "      <td>Restaurants, Dance Clubs, Nightlife, Italian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64284</th>\n",
       "      <td>Was excited to try this place as I love BBQ an...</td>\n",
       "      <td>Mount Horeb</td>\n",
       "      <td>WI</td>\n",
       "      <td>Fast Food, Food, Burgers, Restaurants, Coffee ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174310</th>\n",
       "      <td>Had a groupon for this place.  The serve was g...</td>\n",
       "      <td>Markham</td>\n",
       "      <td>ON</td>\n",
       "      <td>Food, Chicken Wings, Fast Food, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57126</th>\n",
       "      <td>This was our first time ordering from here. We...</td>\n",
       "      <td>Westlake</td>\n",
       "      <td>OH</td>\n",
       "      <td>Pasta Shops, Food, Specialty Food, Italian, Sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127125</th>\n",
       "      <td>NO-SHOW and NO REPLY from \"Customer Service\"\\n...</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Asian Fusion, Chinese, Restaurants, Gluten-Free</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122755</th>\n",
       "      <td>Ordered dinner here recently. Food was some of...</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Restaurants, American (Traditional), Burgers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17555</th>\n",
       "      <td>Great staff Amanda is a doll they took great c...</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>Restaurants, Soup, Pizza, Wraps, Specialty Foo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>We discovered this family run spot and we were...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Restaurants, American (New), Casinos, Educatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182061</th>\n",
       "      <td>Agreed, this place is schwanky! Went for drink...</td>\n",
       "      <td>Madison</td>\n",
       "      <td>WI</td>\n",
       "      <td>Food, Bakeries, Restaurants, Breakfast &amp; Brunch</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>I was visiting from out of town and wanted to ...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>Restaurants, Canadian (New)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>Amazing food. We ordered the barbecue sliders,...</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Delis, Restaurants, Sandwiches</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133542</th>\n",
       "      <td>Good food. Great prices.  Awesome customer ser...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>Sandwiches, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52311</th>\n",
       "      <td>I called concerned about spider webs and they ...</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>OH</td>\n",
       "      <td>Beer, Wine &amp; Spirits, Food, Seafood, Steakhous...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143410</th>\n",
       "      <td>I'm not unfamiliar with Asian Legend - excludi...</td>\n",
       "      <td>Concord</td>\n",
       "      <td>NC</td>\n",
       "      <td>Breakfast &amp; Brunch, Chicken Shop, Fast Food, C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>Sugar, sugar and more sugar. \\n\\nWhat would be...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>Coffee &amp; Tea, Cafes, Restaurants, Food, Delis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71374</th>\n",
       "      <td>Sandwiches were decadent and very popular! Com...</td>\n",
       "      <td>MontrÃ©al</td>\n",
       "      <td>QC</td>\n",
       "      <td>Restaurants, Food, Cafes, Coffee &amp; Tea</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120799</th>\n",
       "      <td>Ok, this place sucked. Order a long island ice...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>Restaurants, Imported Food, Specialty Food, Fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54901</th>\n",
       "      <td>I really like the layout and decor of this pla...</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>Event Planning &amp; Services, Caterers, Italian, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20771</th>\n",
       "      <td>b-e-a-UTIFUL.\\n\\nJust when I thought I was \"ov...</td>\n",
       "      <td>MontrÃ©al</td>\n",
       "      <td>QC</td>\n",
       "      <td>Tapas Bars, Restaurants, Bars, Nightlife, Beer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178098</th>\n",
       "      <td>Old, worn, and tired outlet mall. The only red...</td>\n",
       "      <td>Matthews</td>\n",
       "      <td>NC</td>\n",
       "      <td>Restaurants, Fast Food, Delis, Sandwiches</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37004</th>\n",
       "      <td>This place is so delicious! It is very expensi...</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Sandwiches, Burgers, Mediterranean, Fast Food,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145371</th>\n",
       "      <td>My teeth looked exactly the same after the pro...</td>\n",
       "      <td>Brunswick</td>\n",
       "      <td>OH</td>\n",
       "      <td>Seafood, Thai, Restaurants, Chinese</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176331</th>\n",
       "      <td>this place is the most racist establishment in...</td>\n",
       "      <td>Mount Horeb</td>\n",
       "      <td>WI</td>\n",
       "      <td>Restaurants, Barbeque</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123835</th>\n",
       "      <td>Came here twice in a month. First visit I had ...</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>ON</td>\n",
       "      <td>Indian, Sri Lankan, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>Very nice environment with friendly waitstaff....</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>American (New), Nightlife, Restaurants, Lounge...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51625</th>\n",
       "      <td>Rae was amazing! She was super friendly to our...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>Caribbean, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183140</th>\n",
       "      <td>Loved it, been going here for years! Recently ...</td>\n",
       "      <td>Westlake</td>\n",
       "      <td>OH</td>\n",
       "      <td>Italian, Restaurants</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47496 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text             city  \\\n",
       "45640   Delicious original and unique. Great atmospher...            Tempe   \n",
       "9017    Like many Yelpers, I was eager to try this new...            Tempe   \n",
       "48483   Saturday was a ladies night out. So as I meet ...       North York   \n",
       "102691  This place is great!! Good food, neat atmosphe...         MontrÃ©al   \n",
       "8680    Sunday dinner was okay, not bad but not good. ...         Brampton   \n",
       "48319   Had some extra time to spare at Pearson so I p...        Las Vegas   \n",
       "86369   I've been here twice so far, and the experienc...       Scottsdale   \n",
       "48730   Ow on the other hand this place really not tha...        Las Vegas   \n",
       "72702   Hands down our the best experience of the whol...        Charlotte   \n",
       "112372  My favorite local Italian restaurant in Hender...         Gastonia   \n",
       "60421   The service deserves 5 stars. We went early Ju...  North Las Vegas   \n",
       "29028   Awesome food and Service. Love how they all wo...       Harrisburg   \n",
       "116177  Yay!!! I second the first review!  Blimpie's i...        Las Vegas   \n",
       "87525   Incredible job! I've been going to OohLaLash f...         Glendale   \n",
       "145520  This location accepts Starbucks gift cards as ...          Madison   \n",
       "144674  Excellent restaurant hands down  This restaura...      Scarborough   \n",
       "63485   I used to come here as a kid, because my paren...          Toronto   \n",
       "17702   This was our first time at Block and Grinder a...         MontrÃ©al   \n",
       "76437   Quick and efficient for a burrito.  Had a bean...      Mississauga   \n",
       "186236  Huge portions at decent prices. Love the fact ...        Las Vegas   \n",
       "162905  Menchies.... I love it. I have an obsession wi...        Las Vegas   \n",
       "56146   Best steak house in Charlotte! Service is grea...        Cleveland   \n",
       "173742  You know a restaurant is phenomenal when the f...          Calgary   \n",
       "153097  The downsides: overpriced food, limited menu, ...          Toronto   \n",
       "145602  The crab cakes were awesome as was the wine! M...          Gilbert   \n",
       "133626  A pleasure to work with these guys. They did a...        Las Vegas   \n",
       "115891  I have to give a shout out to Tori who wrote m...          Toronto   \n",
       "27281   Just moved to Brentwood and right down the roa...      Chesterland   \n",
       "31916   I would like to share my incredible experience...          Calgary   \n",
       "141735  Ask for your frappes to be twice blended! Elim...         Chandler   \n",
       "...                                                   ...              ...   \n",
       "134660  Have played several times this year.  Conditio...           Peoria   \n",
       "89265   Loved this place but they had a fire and is no...      Painesville   \n",
       "21197   One of my favorite restaurants in the area. Fo...       Pittsburgh   \n",
       "93215   Great experience! Service, food and atmosphere...         MontrÃ©al   \n",
       "64284   Was excited to try this place as I love BBQ an...      Mount Horeb   \n",
       "174310  Had a groupon for this place.  The serve was g...          Markham   \n",
       "57126   This was our first time ordering from here. We...         Westlake   \n",
       "127125  NO-SHOW and NO REPLY from \"Customer Service\"\\n...       Scottsdale   \n",
       "122755  Ordered dinner here recently. Food was some of...             Mesa   \n",
       "17555   Great staff Amanda is a doll they took great c...       Pittsburgh   \n",
       "7989    We discovered this family run spot and we were...        Las Vegas   \n",
       "182061  Agreed, this place is schwanky! Went for drink...          Madison   \n",
       "2490    I was visiting from out of town and wanted to ...          Toronto   \n",
       "5387    Amazing food. We ordered the barbecue sliders,...          Phoenix   \n",
       "133542  Good food. Great prices.  Awesome customer ser...          Toronto   \n",
       "52311   I called concerned about spider webs and they ...        Cleveland   \n",
       "143410  I'm not unfamiliar with Asian Legend - excludi...          Concord   \n",
       "153155  Sugar, sugar and more sugar. \\n\\nWhat would be...          Toronto   \n",
       "71374   Sandwiches were decadent and very popular! Com...         MontrÃ©al   \n",
       "120799  Ok, this place sucked. Order a long island ice...          Toronto   \n",
       "54901   I really like the layout and decor of this pla...       Pittsburgh   \n",
       "20771   b-e-a-UTIFUL.\\n\\nJust when I thought I was \"ov...         MontrÃ©al   \n",
       "178098  Old, worn, and tired outlet mall. The only red...         Matthews   \n",
       "37004   This place is so delicious! It is very expensi...            Tempe   \n",
       "145371  My teeth looked exactly the same after the pro...        Brunswick   \n",
       "176331  this place is the most racist establishment in...      Mount Horeb   \n",
       "123835  Came here twice in a month. First visit I had ...      Mississauga   \n",
       "2820    Very nice environment with friendly waitstaff....       Scottsdale   \n",
       "51625   Rae was amazing! She was super friendly to our...          Toronto   \n",
       "183140  Loved it, been going here for years! Recently ...         Westlake   \n",
       "\n",
       "       state                                         categories  Nightlife  \\\n",
       "45640     AZ                       Restaurants, Food, Cafeteria          0   \n",
       "9017      AZ                           Steakhouses, Restaurants          0   \n",
       "48483     ON                  Sushi Bars, Restaurants, Japanese          0   \n",
       "102691    QC    Vegetarian, Mediterranean, Restaurants, Falafel          0   \n",
       "8680      ON  Caterers, Nightlife, Caribbean, Restaurants, E...          1   \n",
       "48319     NV  Steakhouses, Bars, Nightlife, Restaurants, Ame...          1   \n",
       "86369     AZ               Restaurants, American (New), Burgers          0   \n",
       "48730     NV                American (Traditional), Restaurants          0   \n",
       "72702     NC          Salad, Sandwiches, Fast Food, Restaurants          0   \n",
       "112372    NC  Southern, Restaurants, Breakfast & Brunch, Mex...          0   \n",
       "60421     NV                               Restaurants, Mexican          0   \n",
       "29028     NC                                Diners, Restaurants          0   \n",
       "116177    NV                     Delis, Sandwiches, Restaurants          0   \n",
       "87525     AZ  Food, Caterers, Restaurants, Event Planning & ...          0   \n",
       "145520    WI  Bars, Burgers, Music Venues, American (New), A...          1   \n",
       "144674    ON                    Restaurants, Breakfast & Brunch          0   \n",
       "63485     ON     Fast Food, Restaurants, Chicken Wings, Seafood          0   \n",
       "17702     QC  Irish, Restaurants, Irish Pub, Nightlife, Pubs...          1   \n",
       "76437     ON                          Asian Fusion, Restaurants          0   \n",
       "186236    NV  Buffets, Restaurants, Japanese, Salad, Korean,...          0   \n",
       "162905    NV  Casinos, Event Planning & Services, Restaurant...          0   \n",
       "56146     OH  Dive Bars, Restaurants, Bars, Nightlife, Ameri...          1   \n",
       "173742    AB  Pubs, Nightlife, American (New), Bars, Restaur...          1   \n",
       "153097    ON             Mexican, Fast Food, Vegan, Restaurants          0   \n",
       "145602    AZ  Mexican, Convenience Stores, Restaurants, Ital...          0   \n",
       "133626    NV  Food, Restaurants, Fast Food, Chicken Wings, C...          0   \n",
       "115891    ON                               Restaurants, Mexican          0   \n",
       "27281     OH                         Chinese, Soup, Restaurants          0   \n",
       "31916     AB                                Indian, Restaurants          0   \n",
       "141735    AZ  Hot Dogs, Ice Cream & Frozen Yogurt, Fast Food...          0   \n",
       "...      ...                                                ...        ...   \n",
       "134660    AZ             Restaurants, Do-It-Yourself Food, Food          0   \n",
       "89265     OH  Restaurants, Breakfast & Brunch, American (Tra...          0   \n",
       "21197     PA                               Italian, Restaurants          0   \n",
       "93215     QC       Restaurants, Dance Clubs, Nightlife, Italian          1   \n",
       "64284     WI  Fast Food, Food, Burgers, Restaurants, Coffee ...          0   \n",
       "174310    ON        Food, Chicken Wings, Fast Food, Restaurants          0   \n",
       "57126     OH  Pasta Shops, Food, Specialty Food, Italian, Sa...          0   \n",
       "127125    AZ    Asian Fusion, Chinese, Restaurants, Gluten-Free          0   \n",
       "122755    AZ       Restaurants, American (Traditional), Burgers          0   \n",
       "17555     PA  Restaurants, Soup, Pizza, Wraps, Specialty Foo...          0   \n",
       "7989      NV  Restaurants, American (New), Casinos, Educatio...          0   \n",
       "182061    WI    Food, Bakeries, Restaurants, Breakfast & Brunch          0   \n",
       "2490      ON                        Restaurants, Canadian (New)          0   \n",
       "5387      AZ                     Delis, Restaurants, Sandwiches          0   \n",
       "133542    ON                            Sandwiches, Restaurants          0   \n",
       "52311     OH  Beer, Wine & Spirits, Food, Seafood, Steakhous...          0   \n",
       "143410    NC  Breakfast & Brunch, Chicken Shop, Fast Food, C...          0   \n",
       "153155    ON      Coffee & Tea, Cafes, Restaurants, Food, Delis          0   \n",
       "71374     QC             Restaurants, Food, Cafes, Coffee & Tea          0   \n",
       "120799    ON  Restaurants, Imported Food, Specialty Food, Fo...          0   \n",
       "54901     PA  Event Planning & Services, Caterers, Italian, ...          0   \n",
       "20771     QC  Tapas Bars, Restaurants, Bars, Nightlife, Beer...          1   \n",
       "178098    NC          Restaurants, Fast Food, Delis, Sandwiches          0   \n",
       "37004     AZ  Sandwiches, Burgers, Mediterranean, Fast Food,...          0   \n",
       "145371    OH                Seafood, Thai, Restaurants, Chinese          0   \n",
       "176331    WI                              Restaurants, Barbeque          0   \n",
       "123835    ON                    Indian, Sri Lankan, Restaurants          0   \n",
       "2820      AZ  American (New), Nightlife, Restaurants, Lounge...          1   \n",
       "51625     ON                             Caribbean, Restaurants          0   \n",
       "183140    OH                               Italian, Restaurants          0   \n",
       "\n",
       "        Pizza  Burger  Chinese  Steak  Sandwiches  Fast Food  \n",
       "45640       0       0        0      0           0          0  \n",
       "9017        0       0        0      1           0          0  \n",
       "48483       0       0        0      0           0          0  \n",
       "102691      0       0        0      0           0          0  \n",
       "8680        0       0        0      0           0          0  \n",
       "48319       0       0        0      1           0          0  \n",
       "86369       0       1        0      0           0          0  \n",
       "48730       0       0        0      0           0          0  \n",
       "72702       0       0        0      0           1          1  \n",
       "112372      0       0        0      0           0          0  \n",
       "60421       0       0        0      0           0          0  \n",
       "29028       0       0        0      0           0          0  \n",
       "116177      0       0        0      0           1          0  \n",
       "87525       0       0        0      0           0          0  \n",
       "145520      0       1        0      0           0          0  \n",
       "144674      0       0        0      0           0          0  \n",
       "63485       0       0        0      0           0          1  \n",
       "17702       0       0        0      0           0          0  \n",
       "76437       0       0        0      0           0          0  \n",
       "186236      0       0        0      0           0          0  \n",
       "162905      0       0        0      0           0          0  \n",
       "56146       0       0        0      0           0          0  \n",
       "173742      0       0        0      0           0          0  \n",
       "153097      0       0        0      0           0          1  \n",
       "145602      0       0        0      0           0          0  \n",
       "133626      0       0        0      0           0          1  \n",
       "115891      0       0        0      0           0          0  \n",
       "27281       0       0        1      0           0          0  \n",
       "31916       0       0        0      0           0          0  \n",
       "141735      0       1        0      0           0          1  \n",
       "...       ...     ...      ...    ...         ...        ...  \n",
       "134660      0       0        0      0           0          0  \n",
       "89265       0       0        0      0           0          0  \n",
       "21197       0       0        0      0           0          0  \n",
       "93215       0       0        0      0           0          0  \n",
       "64284       0       1        0      0           0          1  \n",
       "174310      0       0        0      0           0          1  \n",
       "57126       1       0        0      0           1          0  \n",
       "127125      0       0        1      0           0          0  \n",
       "122755      0       1        0      0           0          0  \n",
       "17555       1       0        0      0           1          0  \n",
       "7989        0       0        0      0           0          0  \n",
       "182061      0       0        0      0           0          0  \n",
       "2490        0       0        0      0           0          0  \n",
       "5387        0       0        0      0           1          0  \n",
       "133542      0       0        0      0           1          0  \n",
       "52311       0       0        0      1           0          0  \n",
       "143410      0       0        0      0           0          1  \n",
       "153155      0       0        0      0           0          0  \n",
       "71374       0       0        0      0           0          0  \n",
       "120799      0       0        0      0           0          0  \n",
       "54901       1       0        0      0           1          0  \n",
       "20771       0       0        0      0           0          0  \n",
       "178098      0       0        0      0           1          1  \n",
       "37004       0       1        0      0           1          1  \n",
       "145371      0       0        1      0           0          0  \n",
       "176331      0       0        0      0           0          0  \n",
       "123835      0       0        0      0           0          0  \n",
       "2820        0       0        0      0           0          0  \n",
       "51625       0       0        0      0           0          0  \n",
       "183140      0       0        0      0           0          0  \n",
       "\n",
       "[47496 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/36909977/update-row-values-where-certain-condition-is-met-in-pandas\n",
    "for cat in common_cats:\n",
    "    X_train.loc[X_train['categories'].str.contains(cat, regex=False), [cat]] = 1\n",
    "    X_test.loc[X_test['categories'].str.contains(cat, regex=False), [cat]] = 1\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train['city'] = X_train['city'].str.lower()\n",
    "X_test['city'] = X_test['city'].str.lower()\n",
    "\n",
    "#X_train['state'] = X_train['state'].str.lower()\n",
    "#X_test['state'] = X_test['state'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(X_train.shape)\n",
    "#X_trainC = pd.get_dummies(X_train['city'], dummy_na=True).to_sparse()\n",
    "#X_testC = pd.get_dummies(X_test['city'], dummy_na=True).to_sparse()\n",
    "#print(X_trainC.shape)\n",
    "#X_testC.head()\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X_train['city'].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<47496x684 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 47496 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainC = enc.transform(X_train['city'].reshape(-1,1))\n",
    "X_testC = enc.transform(X_test['city'].reshape(-1,1))\n",
    "X_trainC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = []\n",
    "for t in enc.categories_:\n",
    "    for c in t:\n",
    "        cities.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agincourt',\n",
       " 'ahwatukee',\n",
       " 'airdrie',\n",
       " 'ajax',\n",
       " 'akron',\n",
       " 'alberta',\n",
       " 'alburg',\n",
       " 'aliquippa',\n",
       " 'allentown',\n",
       " 'allison park',\n",
       " 'ambridge',\n",
       " 'amherst',\n",
       " 'anjou',\n",
       " 'anthem',\n",
       " 'apache junction',\n",
       " 'arnold',\n",
       " 'aspinwall',\n",
       " 'auburn twp',\n",
       " 'aurora',\n",
       " 'avalon',\n",
       " 'avon',\n",
       " 'avon lake',\n",
       " 'avondale',\n",
       " 'bainbridge',\n",
       " 'bainbridge township',\n",
       " 'baldwin',\n",
       " 'balzac',\n",
       " 'bath',\n",
       " 'bay village',\n",
       " 'beachwood',\n",
       " 'beaconsfield',\n",
       " 'beauharnois',\n",
       " 'bedford',\n",
       " 'bedford heights',\n",
       " 'bedford hts.',\n",
       " 'beeton',\n",
       " 'belle vernon',\n",
       " 'belleville',\n",
       " 'bellevue',\n",
       " 'bellvue',\n",
       " 'belmont',\n",
       " 'beloeil',\n",
       " 'berea',\n",
       " 'bethel park',\n",
       " 'black earth',\n",
       " 'blainville',\n",
       " 'blakeney',\n",
       " 'blawnox',\n",
       " 'bloomfield',\n",
       " 'bois-des-filion',\n",
       " 'boisbriand',\n",
       " 'bolton',\n",
       " 'bond head',\n",
       " 'boucherville',\n",
       " 'boulder city',\n",
       " 'braddock',\n",
       " 'bradford',\n",
       " 'bradford west gwillimbury',\n",
       " 'brampton',\n",
       " 'bratenahl',\n",
       " 'brecksville',\n",
       " 'brentwood',\n",
       " 'bridgeville',\n",
       " 'broadview heights',\n",
       " 'brook park',\n",
       " 'brooklin',\n",
       " 'brookline',\n",
       " 'brooklyn',\n",
       " 'brookpark',\n",
       " 'brossard',\n",
       " 'brownsburg-chatham',\n",
       " 'brunswick',\n",
       " 'brunswick hills',\n",
       " 'buckeye',\n",
       " 'buena vista',\n",
       " 'burton',\n",
       " 'caledon',\n",
       " 'caledon east',\n",
       " 'caledon village',\n",
       " 'calgary',\n",
       " 'candiac',\n",
       " 'canonsburd',\n",
       " 'canonsburg',\n",
       " 'carefree',\n",
       " 'carnegie',\n",
       " 'castle shannon',\n",
       " 'catawba springs',\n",
       " 'cave creek',\n",
       " 'cecil',\n",
       " 'central',\n",
       " 'central city',\n",
       " 'central city village',\n",
       " 'chagrin falls',\n",
       " 'chambly',\n",
       " 'champaign',\n",
       " 'champlain',\n",
       " 'chandler',\n",
       " 'chardon',\n",
       " 'chargrin falls',\n",
       " 'charlemagne',\n",
       " 'charlotte',\n",
       " 'chatauguay',\n",
       " 'chateauguay',\n",
       " 'chertsey',\n",
       " 'chesterland',\n",
       " 'chestermere',\n",
       " 'cheswick',\n",
       " 'chomedey, laval',\n",
       " 'church cove',\n",
       " 'chÃ¢teauguay',\n",
       " 'clairton',\n",
       " 'clark',\n",
       " 'clarkson',\n",
       " 'cleveland',\n",
       " 'cleveland heights',\n",
       " 'cleveland hghts.',\n",
       " 'clover',\n",
       " 'columbia station',\n",
       " 'communautÃ©-urbaine-de-montrÃ©al',\n",
       " 'concord',\n",
       " 'concord mills',\n",
       " 'concord township',\n",
       " 'concord twp',\n",
       " 'copley',\n",
       " 'coraopolis',\n",
       " 'cornelius',\n",
       " 'cote saint-luc',\n",
       " 'cote-saint-luc',\n",
       " 'cottage grove',\n",
       " 'crafton',\n",
       " 'cramerton',\n",
       " 'creighton',\n",
       " 'crescent',\n",
       " 'cross plains',\n",
       " 'cuyahoga falls',\n",
       " 'cuyahoga fls',\n",
       " 'cuyahoga heights',\n",
       " 'cÃ´te saint-luc',\n",
       " 'cÃ´te-saint-luc',\n",
       " 'dallas',\n",
       " 'dane',\n",
       " 'davidson',\n",
       " 'de forest',\n",
       " \"de l'eglise\",\n",
       " 'de winton',\n",
       " 'deerfield',\n",
       " 'deforest',\n",
       " 'delson',\n",
       " 'denver',\n",
       " 'deux-montagnes',\n",
       " 'division no. 6',\n",
       " 'dollard-des ormeaux',\n",
       " 'dollard-des-ormeaux',\n",
       " 'don mills',\n",
       " 'dorval',\n",
       " 'downtown',\n",
       " 'dravosburg',\n",
       " 'duquesne',\n",
       " 'east ajax',\n",
       " 'east cleveland',\n",
       " 'east gwillimbury',\n",
       " 'east liberty',\n",
       " 'east mc keesport',\n",
       " 'east mckeesport',\n",
       " 'east pittsburgh',\n",
       " 'east york',\n",
       " 'eastlake',\n",
       " 'edgewood',\n",
       " 'el mirage',\n",
       " 'elizabeth',\n",
       " 'elizabeth township',\n",
       " 'elrama',\n",
       " 'elyria',\n",
       " 'enterprise',\n",
       " 'erie',\n",
       " 'estÃ©rel',\n",
       " 'etna',\n",
       " 'etobicoke',\n",
       " 'etobiicoke',\n",
       " 'euclid',\n",
       " 'export',\n",
       " 'fabreville',\n",
       " 'fairlawn',\n",
       " 'fairport harbor',\n",
       " 'fairview park',\n",
       " 'finleyville',\n",
       " 'fitchburg',\n",
       " 'forest hills',\n",
       " 'fort  mill',\n",
       " 'fort mcdowell',\n",
       " 'fort mill',\n",
       " 'fountain hills',\n",
       " 'ft. mill',\n",
       " 'garfield heights',\n",
       " 'garfield hts',\n",
       " 'gastonia',\n",
       " 'gates mills',\n",
       " 'georgetown',\n",
       " 'gibsonia',\n",
       " 'gifford',\n",
       " 'gilbert',\n",
       " 'glassport',\n",
       " 'glendale',\n",
       " 'glendale az',\n",
       " 'glenshaw',\n",
       " 'godmanchester',\n",
       " 'goodwood',\n",
       " 'goodyear',\n",
       " 'grafton',\n",
       " 'grand river',\n",
       " 'green tree',\n",
       " 'green valley',\n",
       " 'greenfield park',\n",
       " 'guadalupe',\n",
       " 'halton hills',\n",
       " 'hampstead',\n",
       " 'hampton township',\n",
       " 'harmarville',\n",
       " 'harrisburg',\n",
       " 'harrison city',\n",
       " 'heidelberg',\n",
       " 'hemmingford',\n",
       " 'henderson',\n",
       " 'hendersonville',\n",
       " 'henryville',\n",
       " 'herminie',\n",
       " 'highland heights',\n",
       " 'higley',\n",
       " 'hinckley',\n",
       " 'hiram',\n",
       " 'holland landing',\n",
       " 'homer',\n",
       " 'homestead',\n",
       " 'hudson',\n",
       " 'huntersville',\n",
       " 'huntingdon',\n",
       " 'hyland heights',\n",
       " 'iberville',\n",
       " 'imperial',\n",
       " 'independence',\n",
       " 'indian land',\n",
       " 'indian trail',\n",
       " 'inglewood',\n",
       " 'irwin',\n",
       " 'jefferson hills',\n",
       " 'joliette',\n",
       " 'kahnawake',\n",
       " 'kannapolis',\n",
       " 'kennedy township',\n",
       " 'kent',\n",
       " 'king',\n",
       " 'king city',\n",
       " 'kirkland',\n",
       " 'kirtland',\n",
       " 'kleinburg',\n",
       " \"l'assomption\",\n",
       " \"l'ile-perrot\",\n",
       " \"l'Ã®le-bizard\",\n",
       " \"l'Ã®le-perrot\",\n",
       " 'la prairie',\n",
       " 'la salle',\n",
       " 'lachenaie',\n",
       " 'lachine',\n",
       " 'lachute',\n",
       " 'lagrange',\n",
       " 'lake park',\n",
       " 'lake wylie',\n",
       " 'lakewood',\n",
       " 'lancaster',\n",
       " 'las  vegas',\n",
       " 'las vegas',\n",
       " 'lasalle',\n",
       " 'lasvegas',\n",
       " 'laval',\n",
       " 'laval, pont viau',\n",
       " 'laval, ste dorothee',\n",
       " 'lavaltrie',\n",
       " 'laveen',\n",
       " 'laveen village',\n",
       " 'lawrenceville',\n",
       " 'leeds',\n",
       " 'leetsdale',\n",
       " 'library',\n",
       " 'lindale',\n",
       " 'litchfield',\n",
       " 'litchfield park',\n",
       " 'locust',\n",
       " 'longueuil',\n",
       " 'lorain',\n",
       " 'lowell',\n",
       " 'lower burrell',\n",
       " 'lower lawrenceville',\n",
       " 'lowesville',\n",
       " 'lyndhurst',\n",
       " 'macedonia',\n",
       " 'madison',\n",
       " 'mahomet',\n",
       " 'malton',\n",
       " 'mansfield',\n",
       " 'mantua',\n",
       " 'maple',\n",
       " 'maple grove',\n",
       " 'maple heights',\n",
       " 'maricopa',\n",
       " 'markham',\n",
       " 'marshall',\n",
       " 'mascouche',\n",
       " 'mattews',\n",
       " 'matthews',\n",
       " 'mayfield',\n",
       " 'mayfield heights',\n",
       " 'mayfield village',\n",
       " 'mc donald',\n",
       " 'mc farland',\n",
       " 'mc kees rocks',\n",
       " 'mc murray',\n",
       " 'mcadenville',\n",
       " 'mccandless',\n",
       " 'mccandless township',\n",
       " 'mcdonald',\n",
       " 'mcfarland',\n",
       " 'mckees rocks',\n",
       " 'mckeesport',\n",
       " 'mcknight',\n",
       " 'mcmurray',\n",
       " 'medicine hat',\n",
       " 'medina',\n",
       " 'medina township',\n",
       " 'mentor',\n",
       " 'mentor on the',\n",
       " 'mentor on the lake',\n",
       " 'mentor-on-the-lake',\n",
       " 'mercier',\n",
       " 'mesa',\n",
       " 'mesa az',\n",
       " 'middleburg heights',\n",
       " 'middlefield',\n",
       " 'middleton',\n",
       " 'midland',\n",
       " 'midnapore',\n",
       " 'midway',\n",
       " 'millvale',\n",
       " 'milton',\n",
       " 'mint hill',\n",
       " 'mirabel',\n",
       " 'missisauga',\n",
       " 'mississauga',\n",
       " 'mississuaga',\n",
       " 'monona',\n",
       " 'monongahela',\n",
       " 'monroe',\n",
       " 'monroeville',\n",
       " 'mont st-hilaire',\n",
       " 'mont-royal',\n",
       " 'mont-saint-grÃ©goire',\n",
       " 'mont-saint-hilaire',\n",
       " 'monterey park',\n",
       " 'montgomery',\n",
       " 'monticello',\n",
       " 'montreal',\n",
       " 'montreal-est',\n",
       " 'montreal-nord',\n",
       " 'montreal-ouest',\n",
       " 'montreal-west',\n",
       " 'montrose',\n",
       " 'montrÃ©al',\n",
       " 'montrÃ©al-nord',\n",
       " 'montrÃ©al-ouest',\n",
       " 'montrÃ©al-west',\n",
       " 'moon',\n",
       " 'moon township',\n",
       " 'moon twp',\n",
       " 'mooresville',\n",
       " 'moreland hills',\n",
       " 'morgan',\n",
       " 'morin-heights',\n",
       " 'moseley',\n",
       " 'mount albert',\n",
       " 'mount holly',\n",
       " 'mount horeb',\n",
       " 'mount lebanon',\n",
       " 'mount oliver',\n",
       " 'mount washington',\n",
       " 'mt. holly',\n",
       " 'mt. lebanon',\n",
       " 'munhall',\n",
       " 'munroe falls',\n",
       " 'murrysville',\n",
       " 'n las vegas',\n",
       " 'n ridgeville',\n",
       " 'n. las vegas',\n",
       " 'napierville',\n",
       " 'nellis afb',\n",
       " 'nellis air force base',\n",
       " 'neville island',\n",
       " 'new eagle',\n",
       " 'new kensington',\n",
       " 'new tecumseth',\n",
       " 'newbury',\n",
       " 'newmarket',\n",
       " 'nobleton',\n",
       " 'north  york',\n",
       " 'north braddock',\n",
       " 'north huntingdon',\n",
       " 'north huntington',\n",
       " 'north las vegas',\n",
       " 'north olmstead',\n",
       " 'north olmsted',\n",
       " 'north randall',\n",
       " 'north ridgeville',\n",
       " 'north royalton',\n",
       " 'north strabane township',\n",
       " 'north toronto',\n",
       " 'north versailles',\n",
       " 'north york',\n",
       " 'northfield',\n",
       " 'northfield center',\n",
       " 'northfield center township',\n",
       " 'northwest calgary',\n",
       " 'norton',\n",
       " 'oak ridges',\n",
       " 'oakdale',\n",
       " 'oakland',\n",
       " 'oakmont',\n",
       " 'oakridges',\n",
       " 'oakville',\n",
       " 'oakwood',\n",
       " 'ogden',\n",
       " 'oka',\n",
       " 'old port of montreal',\n",
       " 'olmsted falls',\n",
       " 'olmsted township',\n",
       " 'omaha',\n",
       " 'orange',\n",
       " 'orange village',\n",
       " 'oregon',\n",
       " 'outremont',\n",
       " 'pahrump',\n",
       " 'painesville',\n",
       " 'painesville township',\n",
       " 'palgrave',\n",
       " 'paoli',\n",
       " 'paradise',\n",
       " 'paradise valley',\n",
       " 'parma',\n",
       " 'parma heights',\n",
       " 'paw creek',\n",
       " 'peninsula',\n",
       " 'penn hills',\n",
       " 'penn hills township',\n",
       " 'peoria',\n",
       " 'pepper pike',\n",
       " 'perry',\n",
       " 'peters township',\n",
       " 'pheonix',\n",
       " 'pheonix az',\n",
       " 'philo',\n",
       " 'phoenix',\n",
       " 'phoenix valley',\n",
       " 'pickering',\n",
       " 'piedmont',\n",
       " 'pierrefonds',\n",
       " 'pineville',\n",
       " 'pitcairn',\n",
       " 'pittsburgh',\n",
       " 'pleasant hills',\n",
       " 'plum',\n",
       " 'plum boro',\n",
       " 'pointe-aux-trembles',\n",
       " 'pointe-calumet',\n",
       " 'pointe-claire',\n",
       " 'port credit',\n",
       " 'port vue',\n",
       " 'presto',\n",
       " 'prÃ©vost',\n",
       " 'queen creek',\n",
       " 'quÃ©bec',\n",
       " 'ranlo',\n",
       " 'rantoul',\n",
       " 'ravenna',\n",
       " 'rawdon',\n",
       " 'repentigny',\n",
       " 'rexdale',\n",
       " 'richfield',\n",
       " 'richmond heights',\n",
       " 'richmond hil',\n",
       " 'richmond hill',\n",
       " 'richmond hts',\n",
       " 'rigaud',\n",
       " 'rillton',\n",
       " 'river drive park',\n",
       " 'robinson township',\n",
       " 'robinson twp.',\n",
       " 'rock hill',\n",
       " 'rocky river',\n",
       " 'rocky view',\n",
       " 'rocky view county',\n",
       " 'rocky view no. 44',\n",
       " 'rosemere',\n",
       " 'rosemÃ¨re',\n",
       " 'ross',\n",
       " 'ross township',\n",
       " 'rostraver',\n",
       " 'rouses point',\n",
       " 'roxboro',\n",
       " 'russellton',\n",
       " 'sagamore hills',\n",
       " 'saint joseph',\n",
       " 'saint laurent',\n",
       " 'saint leonard',\n",
       " 'saint-basile-le-grand',\n",
       " 'saint-bruno',\n",
       " 'saint-bruno-de-montarville',\n",
       " 'saint-charles-borromee',\n",
       " 'saint-constant',\n",
       " 'saint-eustache',\n",
       " 'saint-henri',\n",
       " 'saint-hubert',\n",
       " 'saint-hyacinthe',\n",
       " 'saint-jean-sur-richelieu',\n",
       " 'saint-jerome',\n",
       " 'saint-jÃ©rÃ´me',\n",
       " 'saint-lambert',\n",
       " 'saint-laurent',\n",
       " 'saint-lazare',\n",
       " 'saint-leonard',\n",
       " 'saint-lÃ©onard',\n",
       " 'saint-marc-sur-richelieu',\n",
       " 'saint-pierre-de-vÃ©ronne-Ã -pike-river',\n",
       " 'saint-sauveur',\n",
       " 'saint-sauveur-des-monts',\n",
       " 'sainte-adele',\n",
       " 'sainte-adÃ¨le',\n",
       " 'sainte-anne-de-bellevue',\n",
       " 'sainte-catherine',\n",
       " 'sainte-dorothÃ©e',\n",
       " 'sainte-genevieve',\n",
       " 'sainte-geneviÃ¨ve',\n",
       " 'sainte-julie',\n",
       " 'sainte-madeleine',\n",
       " 'sainte-marguerite-du-lac-masson',\n",
       " 'sainte-marguerite-esterel',\n",
       " 'sainte-marthe',\n",
       " 'sainte-rose',\n",
       " 'sainte-therese',\n",
       " 'sainte-thÃ©rÃ¨se',\n",
       " 'sainte-thÃ©rÃ¨se-de-blainville',\n",
       " 'saintt-bruno-de-montarville',\n",
       " 'salaberry-de-valleyfield',\n",
       " 'sauk city',\n",
       " 'savoy',\n",
       " 'scarborough',\n",
       " 'scarobrough',\n",
       " 'schomberg',\n",
       " 'schottsdale',\n",
       " 'scottdale',\n",
       " 'scottsdale',\n",
       " 'seven hills',\n",
       " 'sewickley',\n",
       " 'shadyside',\n",
       " 'shaker heights',\n",
       " 'shaler township',\n",
       " 'sharon',\n",
       " 'sharpsburg',\n",
       " 'sheffield',\n",
       " 'sheffield lake',\n",
       " 'sheffield village',\n",
       " 'shorewood hills',\n",
       " 'sidney',\n",
       " 'solon',\n",
       " 'somerton',\n",
       " 'south amherst',\n",
       " 'south euclid',\n",
       " 'south las vegas',\n",
       " 'south park',\n",
       " 'south park township',\n",
       " 'spring hill city view',\n",
       " 'spring valley',\n",
       " 'springdale',\n",
       " 'squirrel hill',\n",
       " 'st joseph',\n",
       " 'st leonard',\n",
       " 'st-bruno-de-montarville',\n",
       " 'st-jean-sur-richelieu',\n",
       " 'st-jerome',\n",
       " 'st-laurent',\n",
       " 'st-leonard',\n",
       " 'stallings',\n",
       " 'stanley',\n",
       " 'ste-dorothÃ©e',\n",
       " 'ste-rose',\n",
       " 'ste-therese-de-blainville',\n",
       " 'stouffville',\n",
       " 'stoughton',\n",
       " 'stow',\n",
       " 'streetsboro',\n",
       " 'streetsville',\n",
       " 'strongsville',\n",
       " 'sturgeon',\n",
       " 'summerlin south',\n",
       " 'sun city',\n",
       " 'sun city west',\n",
       " 'sun lakes',\n",
       " 'sun praiie',\n",
       " 'sun prairie',\n",
       " 'sunrise manor',\n",
       " 'surprise',\n",
       " 'sutersville',\n",
       " 'swissvale',\n",
       " 'tallmadge',\n",
       " 'tarentum',\n",
       " 'tega cay',\n",
       " 'tempe',\n",
       " 'terrebonne',\n",
       " 'thorncliffe park',\n",
       " 'thornhil',\n",
       " 'thornhill',\n",
       " 'tolleson',\n",
       " 'tolono',\n",
       " 'toronto',\n",
       " 'toronto scarborough',\n",
       " 'tottenham',\n",
       " 'township of concord',\n",
       " 'trafford',\n",
       " 'tremont',\n",
       " 'troy township',\n",
       " 'turtle creek',\n",
       " 'tuscola',\n",
       " 'twinsburg',\n",
       " 'unionville',\n",
       " 'university heights',\n",
       " 'upper saint clair',\n",
       " 'upper st clair',\n",
       " 'urbana',\n",
       " 'uxbridge',\n",
       " 'val-morin',\n",
       " 'valley city',\n",
       " 'valley view',\n",
       " 'varennes',\n",
       " 'vaudreuil',\n",
       " 'vaudreuil-dorion',\n",
       " 'vaughan',\n",
       " 'venetia',\n",
       " 'venise-en-quÃ©bec',\n",
       " 'verdun',\n",
       " 'verona',\n",
       " 'ville mont-royal',\n",
       " 'vimont',\n",
       " 'waddell',\n",
       " 'wadsworth',\n",
       " 'walton hills',\n",
       " 'warrensville heights',\n",
       " 'waterloo',\n",
       " 'waunakee',\n",
       " 'waxhaw',\n",
       " 'weddington',\n",
       " 'wesley chapel',\n",
       " 'west elizabeth',\n",
       " 'west homestead',\n",
       " 'west mifflin',\n",
       " 'west view',\n",
       " 'westlake',\n",
       " 'westmount',\n",
       " 'westport',\n",
       " 'wexford',\n",
       " 'whiitby',\n",
       " 'whitby',\n",
       " 'whitchurch-stouffville',\n",
       " 'white oak',\n",
       " 'wickliffe',\n",
       " 'wilkens township',\n",
       " 'wilkins township',\n",
       " 'wilkinsburg',\n",
       " 'willoughby',\n",
       " 'willoughby hills',\n",
       " 'willowdale',\n",
       " 'willowick',\n",
       " 'wilmerding',\n",
       " 'windsor',\n",
       " 'woodbridge',\n",
       " 'woodmere',\n",
       " 'york',\n",
       " 'youngtown',\n",
       " 'Ã®le-des-soeurs']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_df = pd.SparseDataFrame(X_trainC, columns=cities)\n",
    "list(city_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agincourt</th>\n",
       "      <th>ahwatukee</th>\n",
       "      <th>airdrie</th>\n",
       "      <th>ajax</th>\n",
       "      <th>akron</th>\n",
       "      <th>alberta</th>\n",
       "      <th>alburg</th>\n",
       "      <th>aliquippa</th>\n",
       "      <th>allentown</th>\n",
       "      <th>allison park</th>\n",
       "      <th>...</th>\n",
       "      <th>willoughby hills</th>\n",
       "      <th>willowdale</th>\n",
       "      <th>willowick</th>\n",
       "      <th>wilmerding</th>\n",
       "      <th>windsor</th>\n",
       "      <th>woodbridge</th>\n",
       "      <th>woodmere</th>\n",
       "      <th>york</th>\n",
       "      <th>youngtown</th>\n",
       "      <th>Ã®le-des-soeurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 684 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    agincourt  ahwatukee  airdrie  ajax  akron  alberta  alburg  aliquippa  \\\n",
       "31        NaN        NaN      NaN   NaN    NaN      NaN     NaN        NaN   \n",
       "39        NaN        NaN      NaN   NaN    NaN      NaN     NaN        NaN   \n",
       "46        NaN        NaN      NaN   NaN    NaN      NaN     NaN        NaN   \n",
       "50        NaN        NaN      NaN   NaN    NaN      NaN     NaN        NaN   \n",
       "56        NaN        NaN      NaN   NaN    NaN      NaN     NaN        NaN   \n",
       "\n",
       "    allentown  allison park       ...        willoughby hills  willowdale  \\\n",
       "31        NaN           NaN       ...                     NaN         NaN   \n",
       "39        NaN           NaN       ...                     NaN         NaN   \n",
       "46        NaN           NaN       ...                     NaN         NaN   \n",
       "50        NaN           NaN       ...                     NaN         NaN   \n",
       "56        NaN           NaN       ...                     NaN         NaN   \n",
       "\n",
       "    willowick  wilmerding  windsor  woodbridge  woodmere  york  youngtown  \\\n",
       "31        NaN         NaN      NaN         NaN       NaN   NaN        NaN   \n",
       "39        NaN         NaN      NaN         NaN       NaN   NaN        NaN   \n",
       "46        NaN         NaN      NaN         NaN       NaN   NaN        NaN   \n",
       "50        NaN         NaN      NaN         NaN       NaN   NaN        NaN   \n",
       "56        NaN         NaN      NaN         NaN       NaN   NaN        NaN   \n",
       "\n",
       "    Ã®le-des-soeurs  \n",
       "31             NaN  \n",
       "39             NaN  \n",
       "46             NaN  \n",
       "50             NaN  \n",
       "56             NaN  \n",
       "\n",
       "[5 rows x 684 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_df.loc[city_df['phoenix'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enc.inverse_transform([[\"phoenix\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genCity(city):\n",
    "    row = pd.DataFrame(columns=cities)\n",
    "    row.loc[0] = [0]*len(cities)\n",
    "    row.loc[:, city] = 1\n",
    "    row = row.astype('int64')\n",
    "    row = csr_matrix(row.values)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x684 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genCity(\"agincourt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainJ = hstack([tf_train, X_trainC], format=\"csr\")\n",
    "X_testJ = hstack([tf_test, X_testC], format=\"csr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"alpha\":[0.0001, 0.001, 0.01, 0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "ridge_grid = GridSearchCV(estimator=ridge, param_grid=parameters, cv=10, scoring=\"r2\", n_jobs=20)\n",
    "print(ridge_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "ridge_grid.fit(X_trainJ, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(ridge_grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = ridge_grid.cv_results_['mean_test_score']\n",
    "stds = ridge_grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, ridge_grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_grid = GridSearchCV(estimator=lasso, param_grid=parameters, cv=10, scoring=\"r2\", n_jobs=20)\n",
    "print(lasso_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_grid.fit(X_trainJ, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(lasso_grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = lasso_grid.cv_results_['mean_test_score']\n",
    "stds = lasso_grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, lasso_grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElasticNet = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_grid = GridSearchCV(estimator=ElasticNet, param_grid=parameters, cv=10, scoring=\"r2\", n_jobs=20)\n",
    "print(en_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_grid.fit(X_trainJ, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(en_grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = en_grid.cv_results_['mean_test_score']\n",
    "stds = en_grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, en_grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.0001, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_final = ElasticNet(alpha=0.0001)\n",
    "en_final.fit(X_trainJ, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.1585687 , 3.72691187, 3.94407391, ..., 0.08736341, 3.70186236,\n",
       "       3.57353303])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = en_final.predict(X_testJ)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6210968619978035"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "\n",
    "    text_tf = vectorizer.transform(text)\n",
    "\n",
    "    #text_lower = text.str.lower()\n",
    "    text_lower = text[0].lower()\n",
    "\n",
    "    #text_enc = enc.transform(text_lower.reshape(-1,1))\n",
    "    text_enc = enc.transform([[text_lower]])\n",
    "\n",
    "    text_joined = hstack([text_tf, text_enc], format=\"csr\")\n",
    "    return en_final.predict(text_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_city(text, city):\n",
    "\n",
    "    text_tf = vectorizer.transform(text)\n",
    "    text_enc = genCity(city)\n",
    "\n",
    "    text_joined = hstack([text_tf, text_enc], format=\"csr\")\n",
    "    return en_final.predict(text_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict([\"this is a review\"]))\n",
    "print(predict([\"This is a great restaurant!\"]))\n",
    "print(predict([\"This is a bad restaurant!\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_city([\"this is a review\"], \"phoenix\"))\n",
    "print(predict_city([\"this is a review\"], \"las vegas\"))\n",
    "#print(predict_city([\"this is a review\"], \"boston\"))\n",
    "print()\n",
    "print(predict_city([\"This is a great restaurant!\"], \"phoenix\"))\n",
    "print(predict_city([\"This is a great restaurant!\"], \"las vegas\"))\n",
    "#print(predict_city([\"This is a great restaurant!\"], \"boston\"))\n",
    "print()\n",
    "print(predict_city([\"This is a bad restaurant!\"], \"phoenix\"))\n",
    "print(predict_city([\"This is a bad restaurant!\"], \"las vegas\"))\n",
    "#print(predict_city([\"This is a bad restaurant!\"], \"boston\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pickle.dumps(en_final)\n",
    "p = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_predict(text):\n",
    "\n",
    "    text_tf = vectorizer.transform(text)\n",
    "\n",
    "    #text_lower = text.str.lower()\n",
    "    text_lower = text[0].lower()\n",
    "\n",
    "    #text_enc = enc.transform(text_lower.reshape(-1,1))\n",
    "    text_enc = enc.transform([[text_lower]])\n",
    "\n",
    "    text_joined = hstack([text_tf, text_enc], format=\"csr\")\n",
    "    return p.predict(text_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pickle_predict([\"this is a review\"]))\n",
    "print(pickle_predict([\"This is a great restaurant!\"]))\n",
    "print(pickle_predict([\"This is a bad restaurant!\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainJS = pd.SparseDataFrame(X_trainJ)\n",
    "X_trainJS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
