
<video src="Demo Video.mov" width="320" height="200" controls preload></video>


<h1>Text Analysis of the Yelp Dataset</h1>
<h2>Matt D’Intino & Victor Liang DS 5500 April 2019 </h2>

<h3>Motivation:</h3>
A restaurateur looking to open a new restaurant or expand an existing restaurant to a new location is faced with the following problem: “what type of restaurant would have the highest success in this location, or what location would make this type of restaurant the most successful?” Using text reviews curated by the website Yelp, this study investigates the effects of location and restaurant type on a reviewer’s rating of a restaurant. The hypothesis being tested is that users in one American city will rate restaurants of a certain type differently than users in another American city, and these ratings are a reasonable indication of the restaurant’s success.

<h3>Data Analysis:</h3>
This project utilized a dataset cultivated by Yelp and made available on Kaggle (https://www.yelp.com/dataset/documentation/main) to build multiple machine learning algorithms and resulting visualizations. Yelp is a website that allows for users to leave reviews on consumer businesses so that other potential customers have an idea of what he or she might get if they decide to engage with the given business. These reviews involve a text description and a star rating from 1-5. The Yelp dataset contains multiple json files, but only two were used in this study: “business” and “review”. The business file contains information about the businesses themselves. The relevant fields from the business file for this study are ‘city’, which describes the business’ location, and ‘category’, which returns a list of traits that describe the business. An example ‘category’ field is as follows: [‘Sushi Bars’, ‘Restaurants’, ‘Japanese’]. As previously mentioned, the review file contains the actual text of a user review, as well as a star rating on a scale of 1-5, 1 being the worst and 5 being the best. Both the business file and the review file contain a ‘business_id’ field, which allows for joining the reviews with the associated business.
<p></p>
<i>Example records:</i>
<p></p>
<u>Business:</u>
<p></p>
<img src="Table1.png" width="600" height="800">
<p></p>
<u>Review:</u>
<p></p>
<img src="Table2.png" width="600" height="800">
<p></p>
The business.json file was loaded and merged with the review.json using an inner join. The join result contained data from a wide array of establishments from nail salons to plumbers to restaurants, so it was filtered to only contain records that had the string “Restaurants” in the ‘category’ column. This filter operation left approximately 60,000 restaurant-associated text reviews.
The business data was heavily dominated by a small number of cities. For example, there were thousands of records from Las Vegas, but none from New York City. For this reason, this study pivoted from focusing on the entire United States to specific cities with sufficient data, namely Las Vegas NV, Charlotte NC, Madison WI, Phoenix AZ, and Pittsburgh PA.

<h3>Task Analysis:</h3>
The goal of this study is to produce a model and visualization to communicate how successful a potential restaurant would be in a specific area. To do this, a model should be built whose output is an expected star rating (1-5) for a restaurant based on a list of attributes and a sample description, to serve as an analogous review, as input. The hypothesis being tested expects that these scores will vary by location, so one element of the visualization should involve entering a list of categories and producing a bar chart indicating expected star ratings in different cities. This visualization should also contain model outputs that show how much certain restaurants attributes contribute to success in different areas of the US.
<p></p>
<img src="Table3.png" width="600" height="300">
<p></p>
This visualization will primarily be developed for the “present” type of consumption. It will use simple visual encodings to show how the success of similar restaurants change with location, as well as which restaurant attributes most contribute to success or failure. These tasks are linked to the “present” concept because they involve looking to communicate high level trends within the data. The primary consumer of the visualization will be restaurateurs looking to either expand a current restaurant to a new US location, or to open up a totally new restaurant in a given city. In both scenarios the required information will be provided by showing what types of restaurants are expected to succeed in which locations.

<h3>Model Description:</h3>
<i>Linear Regression</i>
Linear regression is a machine learning technique that involves producing a numerical predicted output on a linear scale. In this case, the predicted output will be replicating Yelp’s 1-5 star ratings, and will use text features from reviews and location and type of the restaurant to build its predictions. To begin this process, the text, city, and category list were extracted and split into train and test sets using an 80%/20% breakdown. A TF-IDF vectorizer was then trained on the text of the training set with ‘min_df’ set to 0.01. The text from both train and test sets was then transformed by the TF-IDF vectorizer.
    Next, a one-hot encoding approach was used on the ‘categories’ field to search for specific restaurant types. The categories chosen for this dataset were ‘Pizza’, ‘Mexican’, ‘Chinese’, ‘Italian’, and ‘Vietnamese’ because they were sufficiently common and distinct. DataFrame columns representing each of these common categories were filled with 0’s and appended to the train and test datasets. Then each row was searched for each category using the same str.contains approach that was
    implemented for the restaurant filtering. If the category was found, the appropriate column value was replaced with a 1. The train and test sets were then converted to csr_matrices. 
The city field in both train and test sets was converted to all lower case to control for simple typographical data quality issues, and the training set’s city field was fit to the sklearn.preprocessing OneHotEncoder. This model was then used to transform both the train and test sets’ city fields. The city names were then stored in an array using the enc.categories_ method to be used to encode city values when running the model on new input. All three outputs, the tf-idf matrix, the one-hot encoded city, and the one-hot encoded category matrices were joined using the hstack function from scipy.
Next, a grid search was run using alpha values of [0.0001, 0.001, 0.01, 0.1] for three types of linear regression: ridge, lasso, and elastic net. The alpha parameter was the only variable for the grid search due to its consistency across all three of the chosen models. The grid search was run with 10 fold cross validation, n_jobs=20, and scoring=”r2”. Using ‘mean_test_score’ and ‘std_test_score’ from the ridge_grid function’s performance on the train set, ElasticNet(alpha=0.0001) was determined to be the best model. This model produced an r2 score of 0.6210477250037865 when comparing its predictions on the test set to the test set’s true values.
This model was then embedded in the web interface, along with the associated tf-idf vectorizer and one-hot encoding methods to manipulate the user input to match that of the train and test sets. These objects were stored and accessed using the ‘pickle’ library. Because the models being used were linear regression, the model will in some scenarios predict a score outside of Yelp’s 1-5 range. In these cases, simple if/else logic was applied to store an prediction less than 1 as 1, and any prediction more than 5 as 5.
